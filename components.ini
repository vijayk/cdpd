#[component-name]
# HDP_VERSION -> Distro.ini
# git_url -> hdp-base.json
# branch -> hdp-base.json
# comp_version -> hdp-base.json
# BUILD_NUMBER -> jenkins Env
# package_count. this file -> overriden by platfom_components.txt
# build_tool -> this file
# install.cmd -> this file
# deploy.cmd  -> this file
# UnitTest Command -> this file
# depends_on -> hdp-base.json
# text-replace, xml-replace, xpath-replace - for replacing versions in component code

[accumulo]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN_CMD} -Dfindbugs.skip=true -Pdocs,assemble -Dhadoop.profile=2 -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Drepourl=${NEXUS_REPO_URL} -Dreponame=${NEXUS_DEPLOY_REPO_ID} ${MAVEN_TEST_OPTS}"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${accumulo_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} -DskipTests -DskipITs deploy

    [[artifacts]]
        artifact_1 = assemble/target/accumulo-${accumulo_jar_version}-bin.tar.gz
        artifact_2 = server/native/target/accumulo-native-${accumulo_jar_version}/accumulo-native-${accumulo_jar_version}/libaccumulo.so
        artifact_3 = test.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} -DskipTests -DskipITs install -Dmaven.javadoc.skip=true
        cmd_2 = "tar --exclude-vcs -zcf test.tar.gz test"

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} clean package -Dmvn.version=2.1.3 -Dsurefire.timeout=2400

    [[xml-replace]]
        REPLACE_1 = 'hadoop.version' , ${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'zookeeper.version' , ${zookeeper_jar_version}, pom.xml

# TODO (sriharsha) figure out hbase, solr version from pom.xml , BUG-58027 cached apache archive tar to s3.
# https://github.com/hortonworks/build-support/commit/6a258920f96f89aa7bec590734db69cf878c42a9
[atlas]
build_tool = maven
atlas_alternate_name = apache-atlas
hbase_pkg_version = 1.1.2
solr_pkg_version = 5.1.0
COMMON_BUILD_OPTS = "${MVN_CMD} -Dfindbugs.skip=true -Pgpg -DskipDocs=true -Dhadoop.version=${hadoop_jar_version} -Dzookeeper.version=${zookeeper_jar_version} -Dinternal.maven.repository=${NEXUS_REPO_URL} -DStagingId=${NEXUS_DEPLOY_REPO_ID} -DStagingUrl=${NEXUS_REPO_URL} -Dhbase.tar=http://public-repo-1.hortonworks.com/ARTIFACTS/dist/hbase/${hbase_pkg_version}/hbase-${hbase_pkg_version}-bin.tar.gz -Dsolr.tar=http://public-repo-1.hortonworks.com/ARTIFACTS/dist/lucene/solr/${solr_pkg_version}/solr-${solr_pkg_version}.tgz"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${atlas_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} -Pdist -DskipTests -DskipITs deploy assembly:assembly
package_count = 3

    [[artifacts]]
        artifact_1 = distro/target/${atlas_alternate_name}-${atlas_jar_version}-bin.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} -Pdist -DskipTests -DskipITs install

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} --fail-at-end clean verify -Dsurefire.timeout=300

    [[xml-replace]]
        REPLACE_1 = 'hadoop.version' , ${hadoop_jar_version} , pom.xml
        REPLACE_2 = 'hive.version' , ${hive_jar_version} , pom.xml
        REPLACE_3 = 'calcite.version', ${calcite_jar_version} , pom.xml
        REPLACE_4 = 'zookeeper.version' , ${zookeeper_jar_version} , pom.xml
        REPLACE_5 = 'hbase.version' , ${hbase_jar_version} , pom.xml
        REPLACE_6 = 'falcon.version' , ${falcon_jar_version} , pom.xml
        REPLACE_7 = 'storm.version' , ${storm_jar_version} , pom.xml
        REPLACE_8 = 'sqoop.version' , ${sqoop_jar_version} , pom.xml
        REPLACE_9 = 'kafka.version', ${kafka_jar_version} , pom.xml


[avatica]
build_tool = maven
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${avatica_jar_version} , avatica
deploy_cmd = "${MVN_CMD} deploy -Drepo.id=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.repo=${NEXUS_REPO_URL} -DskipITs -DskipTests"
no_package = True

    [[install_cmd]]
        cmd_1 = ${MVN_CMD} install package -DskipITs -DskipTests , avatica
        
    [[test_cmd]]
        cmd_1 = ${MVN_CMD} test

[bigtop-tomcat]
build_tool = ant
    [[install_cmd]]
        cmd_0 = mkdir -p ${TAR_DIR}/bigtop-tomcat , ${BASE_DIR}
        cmd_1 = "wget -O ${TAR_DIR}/bigtop-tomcat/apache-tomcat-${TOMCAT_VERSION}.tar.gz http://dev.hortonworks.com.s3.amazonaws.com/ARTIFACTS/dist/tomcat/tomcat-6/v${TOMCAT_VERSION}/bin/apache-tomcat-${TOMCAT_VERSION}.tar.gz", ${BASE_DIR}

[bigtop-jsvc]
build_tool = ant
    [[install_cmd]]
        cmd_0 = mkdir -p ${TAR_DIR}/bigtop-jsvc , ${BASE_DIR}
        cmd_1 = "wget -O ${TAR_DIR}/bigtop-jsvc/commons-daemon-${JSVC_VERSION}.tar.gz http://dev.hortonworks.com.s3.amazonaws.com/ARTIFACTS/dist/commons/daemon/source/commons-daemon-${JSVC_VERSION}-native-src.tar.gz" , ${BASE_DIR}

[calcite]
build_tool = maven
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${calcite_jar_version}
deploy_cmd = "${MVN_CMD} deploy -Drepo.id=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.repo=${NEXUS_REPO_URL} -DskipITs -DskipTests"
no_package = True

    [[install_cmd]]
        cmd_1 = ${MVN_CMD} install package -DskipITs -DskipTests

    [[test_cmd]]
        cmd_1 = ${MVN_CMD} test

    [[xml-replace]]
        REPLACE_1 = 'activeByDefault' , false , pom.xml
        REPLACE_2 = 'avatica.version' , ${avatica_jar_version}, pom.xml

[calcite_hive2]
build_tool = maven
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${calcite_hive2_jar_version}
deploy_cmd = "${MVN_CMD} deploy -Drepo.id=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.repo=${NEXUS_REPO_URL} -DskipITs -DskipTests"
no_package = True

    [[install_cmd]]
        cmd_1 = ${MVN_CMD} install package -DskipITs -DskipTests
        
    [[test_cmd]]
        cmd_1 = ${MVN_CMD} test

    [[xml-replace]]
        REPLACE_1 = 'activeByDefault' , false , pom.xml
        REPLACE_2 = 'avatica.version' , ${avatica_jar_version}, pom.xml

[datafu]
build_tool = gradle

    [[artifacts]]
        artifact_1 = datafu-pig/build/libs/datafu-pig-${datafu_jar_version}.jar
        artifact_2 = datafu-pig/build/libs/datafu-pig-${datafu_jar_version}-core.jar
        artifact_3 = datafu-pig/build/libs/datafu-pig-${datafu_jar_version}-javadoc.jar
        artifact_4 = datafu-pig/build/libs/datafu-pig-${datafu_jar_version}-sources.jar

    [[install_cmd]]
        cmd_0 = ${GRADLE_CMD} -b bootstrap.gradle
        cmd_1 = ./gradlew -Pversion=${datafu_jar_version} -Prelease=true :datafu-pig:assemble install

    [[test_cmd]]
        cmd_0 = ${GRADLE_CMD} -b bootstrap.gradle
        cmd_1 = ./gradlew -Pversion=${datafu_jar_version} -Prelease=true :datafu-pig:test
    [[text-replace]]
        REPLACE_1 = "datafu-pig-incubating","datafu-pig", datafu-pig/build.gradle , regex_replace

[druid]
build_tool = maven
setversion_cmd = ${MVN333_CMD} org.codehaus.mojo:versions-maven-plugin:2.1:set -DgenerateBackupPoms=false -DnewVersion=${druid_jar_version}
deploy_cmd = "${MVN333_CMD} deploy -Drepo.id=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.repo=${NEXUS_REPO_URL} -DskipITs -DskipTests"

    [[artifacts]]
        artifact_1 = distribution/target/druid-${druid_jar_version}-bin.tar.gz

    [[install_cmd]]
        cmd_1 = ${MVN333_CMD} -DskipTests clean install

    [[test_cmd]]
        cmd_1 = ${MVN333_CMD} clean test

    [[xml-replace]]
        REPLACE_1 = 'hadoop.compile.version', ${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'hive.version', ${hive2_jar_version}, pom.xml

    [[text-replace]]
        REPLACE_1 = '"https://repo1.maven.org/maven2/"', '"https://repo1.maven.org/maven2/", "${NEXUS_PROXY_URL}"', services/src/main/java/io/druid/cli/PullDependencies.java, regex_replace
        REPLACE_2 = 'org.apache.hadoop:hadoop-client:2.3.0', org.apache.hadoop:hadoop-client:${hadoop_jar_version}, indexing-service/src/main/java/io/druid/indexing/common/config/TaskConfig.java, regex_replace

[falcon]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN_CMD} -Phadoop-2,hwx-common,adf,hdfs-snapshot-mirroring,hivedr -DskipCheck=true -Dcheckstyle.skip=true -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Drepourl=${NEXUS_REPO_URL} -Dreponame=${NEXUS_DEPLOY_REPO_ID} ${MAVEN_TEST_OPTS}"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${falcon_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} deploy -DskipITs -DskipTests assembly:assembly

    [[artifacts]]
        artifact_1 = distro/target/falcon-${falcon_jar_version}-bin.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} install -DskipITs -DskipTests assembly:assembly

    [[test_cmd]]
        cmd_1 = "${MVN_CMD} clean test -Phadoop-2,hwx-common,adf,hdfs-snapshot-mirroring,hivedr-DskipITs -DskipITs -Dsurefire.timeout=3600"

    [[xml-replace]]
        REPLACE_1 = 'activeByDefault','false', pom.xml
        REPLACE_2 = 'hadoop.version',${hadoop_jar_version}, pom.xml
        REPLACE_3 = 'hadoop2.version',${hadoop_jar_version}, pom.xml
        REPLACE_4 = 'hive.version',${hive_jar_version}, pom.xml
        REPLACE_5 = 'hcatalog.version',${hive_jar_version}, pom.xml
        REPLACE_6 = 'oozie.version',${oozie_jar_version}, pom.xml
        REPLACE_7 = 'jetty.version' , ${jetty_hwx_version} , pom.xml
        REPLACE_8 = 'zookeeper.version',${zookeeper_jar_version}, pom.xml

[flume]
build_tool = maven
atlas_alternate_name = apache-flume
COMMON_BUILD_OPTS = "${MVN_CMD} -Dflume.hadoop.profile=hbase-98 -Dhadoop-two.version=${hadoop_jar_version} -Dhadoop2.version=${hadoop_jar_version} -Dhbaseversion=${hbase_jar_version} -Dzookeeper.version=${zookeeper_jar_version} -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Dreponame=${NEXUS_DEPLOY_REPO_ID} -Drepourl=${NEXUS_REPO_URL} -Drepo.maven.org=${NEXUS_PROXY_URL} -Psign,gpg"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${flume_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} deploy -DskipITs -DskipTests -Psite -Dmaven.javadoc.skip=true
package_count = 3

    [[artifacts]]
        artifact_1 = flume-ng-dist/target/${atlas_alternate_name}-${flume_jar_version}-bin.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} install -DskipITs -DskipTests -Psite -Dmaven.javadoc.skip=true
        
    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} -fae test -Dsurefire.timeout=3000

    [[xml-replace]]
        REPLACE_1 = 'hadoop.version' , ${hadoop_jar_version} , pom.xml
        REPLACE_2 = 'hbase.version' , ${hbase_jar_version} , pom.xml
        REPLACE_3 = 'hive.version' , ${hive_jar_version} , pom.xml
        REPLACE_4 = 'kafka.version' , ${kafka_jar_version} , pom.xml
        REPLACE_5 = 'jetty.version' , ${jetty_hwx_version} , pom.xml
        REPLACE_6 = 'zookeeper.version' , ${zookeeper_jar_version} , pom.xml

[hadoop]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN_CMD} -Drequire.snappy=true -Dbundle.snappy=true -Dsnappy.prefix=x -Dsnappy.lib=${snappylib} -Pdist -Pnative -Dtar -Psrc -Pgpg -Psign  -Drequire.openssl=true -Dtomcat.download.url='${PUBLIC_REPO_URL}/ARTIFACTS/dist/tomcat/tomcat-6/v${TOMCAT_VERSION}/bin/apache-tomcat-${TOMCAT_VERSION}.tar.gz'"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${hadoop_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} -DdistMgmtStagingId=${NEXUS_DEPLOY_REPO_ID} -DdistMgmtStagingUrl=${NEXUS_REPO_URL} -DskipTests -DskipITs deploy

    [[artifacts]]
        artifact_1 = hadoop-dist/target/hadoop-${hadoop_jar_version}.tar.gz
        artifact_2 = hadoop-client/target/hadoop-client-${hadoop_jar_version}.tar.gz
        artifact_3 = hadoop-hdfs-project/hadoop-hdfs/target/hadoop-hdfs-${hadoop_jar_version}.tar.gz
        artifact_4 = hadoop-hdfs-project/hadoop-hdfs/target/native/main/native/fuse-dfs/fuse_dfs

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} -DdistMgmtStagingId=${NEXUS_DEPLOY_REPO_ID} -DdistMgmtStagingUrl=${NEXUS_REPO_URL} -DskipTests -DskipITs install
        cmd_2 = ${COMMON_BUILD_OPTS} -DdistMgmtStagingId=${NEXUS_DEPLOY_REPO_ID} -DdistMgmtStagingUrl=${NEXUS_REPO_URL} -DskipTests -DskipITs site:site
        
    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} ${MAVEN_TEST_OPTS} clean test -Dsurefire.timeout=2400

    [[xml-replace]]
        REPLACE_1 = 'forkedProcessTimeoutInSeconds', '1800' , hadoop-project/pom.xml
        REPLACE_2 = 'forkedProcessTimeoutInSeconds', '1800' , hadoop-tools/hadoop-distcp/pom.xml
        REPLACE_3 = 'argLine', '-Xms2048m -Xmx3072m -XX:MaxPermSize=2048m -XX:+HeapDumpOnOutOfMemoryError', hadoop-project/pom.xml
        REPLACE_4 = 'argLine', '-Xms2048m -Xmx3072m -XX:MaxPermSize=2048m -XX:+HeapDumpOnOutOfMemoryError', hadoop-tools/hadoop-distcp/pom.xml
        REPLACE_5 = 'zookeeper.version', ${zookeeper_jar_version} , pom.xml
        REPLACE_6 = 'jetty.version' , ${jetty_hwx_version} , pom.xml


[hadooplzo]
build_tool = maven
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${hadooplzo_jar_version}

    [[artifacts]]
        artifact_1 = target/hadooplzo-${hadooplzo_jar_version}.tar.gz

    [[install_cmd]]
        cmd_1 = "${MVN_CMD} -Dversion=${hadooplzo_jar_version} -Dhadoop.version=${hadoop_jar_version} -Drepo.maven.org=${NEXUS_REPO_URL} -Dmvnrepo=${NEXUS_REPO_URL} clean install package"
        cmd_2 = "tar -zvcf hadooplzo-${hadooplzo_jar_version}.tar.gz native hadoop-lzo-${hadooplzo_jar_version}.jar hadoop-lzo-${hadooplzo_jar_version}-javadoc.jar hadoop-lzo-${hadooplzo_jar_version}-sources.jar --exclude=native/Linux-amd64-64/src --exclude=native/Linux-amd64-64/.libs --exclude=native/Linux-amd64-64/impl --exclude=native/Linux-amd64-64/libgplcompression.la --exclude=native/Linux-amd64-64/Makefile --exclude=native/Linux-amd64-64/config.status --exclude=native/Linux-amd64-64/config.log --exclude=native/Linux-amd64-64/libtool" , target

    [[xml-replace]]
        REPLACE_1 = 'hadoop.current.version', ${hadoop_jar_version} , pom.xml

[hbase]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN_CMD} -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Drepourl=${NEXUS_REPO_URL} clean"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${hbase_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} deploy javadoc:aggregate site package assembly:single -DskipTests=true -Dmaven.javadoc.skip=true

    [[artifacts]]
        artifact_1 = hbase-assembly/target/hbase-${hbase_jar_version}.tar.gz
        artifact_2 = hbase-thrift/src/main/resources/org/apache/hadoop/hbase/thrift/Hbase.thrift
        artifact_3 = hbase-thrift/src/main/resources/org/apache/hadoop/hbase/thrift2/hbase.thrift

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} install javadoc:aggregate site package assembly:single -DskipTests=true -Dmaven.javadoc.skip=true
        
   [[test_cmd]]
	cmd_1 = ${COMMON_BUILD_OPTS} install -DskipTests -Pcompile-protobuf
        cmd_2 = ${COMMON_BUILD_OPTS} -X -e -fae -Dhadoop.version=${hadoop_jar_version} -Dpackage.version=${hadoop_jar_version} -Dzookeeper.version=${zookeeper_jar_version} -Phadoop-2.0 install ${MAVEN_TEST_OPTS} -Dmaven.test.redirectTestOutputToFile=true -DskipITs -Dsurefire.firstPartThreadCount=1 -Dsurefire.secondPartThreadCount=2  -Dsurefire.timeout=2400

    [[xml-replace]]
        REPLACE_1 = 'hadoop-one.version',${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'hadoop-two.version', ${hadoop_jar_version}, pom.xml
        REPLACE_3 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml
        REPLACE_4 = 'surefire.firstPartThreadCount', '1', pom.xml
        REPLACE_5 = 'surefire.secondPartThreadCount', '1', pom.xml
        REPLACE_6 = 'surefire.timeout', '7200', pom.xml
        REPLACE_7 = 'activeByDefault' , 'false' , pom.xml
        REPLACE_8 = 'hbase.version' , ${hbase_jar_version} , pom.xml
        REPLACE_9 = 'jetty.version' , ${jetty_hwx_version} , pom.xml

[hive]
build_tool = maven
hive_alternate_name = apache-hive
hive_apache_base_maven_version = 1.2.1
COMMON_BUILD_OPTS = "${MVN_CMD} -Dhadoop.mr.rev=23 -DskipSparkTests -Drepo.maven.org=${NEXUS_PROXY_URL} -Dtest.junit.output.format=xml -Dmvn.hadoop.profile=hadoop23 -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Drepourl=${NEXUS_REPO_URL} -Dmvnrepo=${NEXUS_PROXY_URL}"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${hive_jar_version}
deploy_cmd = "${COMMON_BUILD_OPTS} clean deploy -DskipTests -Phadoop-2,dist,sources"

    [[artifacts]]
        artifact_1 = packaging/target/${hive_alternate_name}-${hive_jar_version}-bin.tar.gz

    [[install_cmd]]
        cmd_1 = "${COMMON_BUILD_OPTS} clean  install -DskipTests -Phadoop-2,dist,sources -Dmaven.javadoc.skip=true"

           # TODO (sriharsha) https://github.com/hortonworks/build-support/blob/54e21777991d904dfb0da2074a41c8b858cb9e10/SubstitutionFiles/hive.sh#L20 and L21
           # replace old contents

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} test-compile -Dhadoop-23.version=${hadoop_jar_version} -Phadoop-2 ${MAVEN_TEST_OPTS}
        cmd_2 = ${COMMON_BUILD_OPTS} test -Dhadoop-23.version=${hadoop_jar_version} -Phadoop-2 ${MAVEN_TEST_OPTS}
        cmd_3 = ${COMMON_BUILD_OPTS} test-compile -Dhadoop-23.version=${hadoop_jar_version} -Phadoop-2

    [[text-replace]]
        REPLACE_1 = "${hive_apache_base_maven_version}-SNAPSHOT", ${hive_jar_version}, pom.xml , key_value
        REPLACE_2 = "${hive_apache_base_maven_version}", ${hive_jar_version}, pom.xml , key_value

    [[xml-replace]]
        REPLACE_1 = 'accumulo.version', ${accumulo_jar_version}, pom.xml
        REPLACE_2 = 'calcite.version', ${calcite_jar_version}, pom.xml
        REPLACE_3 = 'hadoop-23.version', ${hadoop_jar_version}, pom.xml
        REPLACE_4 = 'hbase.version', ${hbase_jar_version}, pom.xml
        REPLACE_5 = 'hbase.hadoop2.version', ${hbase_jar_version}, pom.xml
        REPLACE_6 = 'tez.version', ${tez_jar_version}, pom.xml
        REPLACE_7 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml
        REPLACE_8 = 'avatica.version', ${avatica_jar_version}, pom.xml

[hive2]
build_tool = maven
hive_alternate_name = apache-hive
hive_apache_base_maven_version = 1.2.1
COMMON_BUILD_OPTS = "${MVN_CMD} -Dhadoop.mr.rev=23 -DskipSparkTests -Drepo.maven.org=${NEXUS_PROXY_URL} -Dtest.junit.output.format=xml -Dmvn.hadoop.profile=hadoop23 -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Drepourl=${NEXUS_REPO_URL} -Dmvnrepo=${NEXUS_PROXY_URL}"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${hive2_jar_version}
deploy_cmd = "${COMMON_BUILD_OPTS} clean deploy -DskipTests -Phadoop-2,dist,sources"

    [[artifacts]]
        artifact_1 = packaging/target/${hive_alternate_name}-${hive2_jar_version}-bin.tar.gz

    [[install_cmd]]
        cmd_1 = "${COMMON_BUILD_OPTS} clean  install -DskipTests -Phadoop-2,dist,sources -Dmaven.javadoc.skip=true"

    [[test_cmd]]
        cmd_1 = "${COMMON_BUILD_OPTS} test-compile -Dmaven.test.failure.ignore=true"

    [[text-replace]]
        REPLACE_1 = "${hive_apache_base_maven_version}-SNAPSHOT", ${hive2_jar_version}, pom.xml , key_value
        REPLACE_2 = "${hive_apache_base_maven_version}", ${hive2_jar_version}, pom.xml , key_value

    [[xml-replace]]
        REPLACE_1 = 'accumulo.version', ${accumulo_jar_version}, pom.xml
        REPLACE_2 = 'calcite.version', ${calcite_hive2_jar_version}, pom.xml
        REPLACE_3 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_4 = 'hbase.version', ${hbase_jar_version}, pom.xml
        REPLACE_5 = 'hbase.hadoop2.version', ${hbase_jar_version}, pom.xml
        REPLACE_6 = 'tez.version', ${tez_hive2_jar_version}, pom.xml
        REPLACE_7 = 'avatica.version', ${avatica_jar_version}, pom.xml
        REPLACE_8 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml
        REPLACE_9 = 'slider.version', ${slider_jar_version}, pom.xml

[hue]
build_tool = maven
package_count = 8
    [[artifacts]]
        artifact_1 = hue.tar.gz

    [[install_cmd]]
        cmd_1 = "make apps" , hue
        cmd_2 = bash tools/relocatable.sh , hue
        cmd_3 = "tar -cz --exclude-vcs --transform 's,^\.\/,hue/,' -f /tmp/hue.tar.gz ."
        cmd_4 = "mv /tmp/hue.tar.gz ."

[kafka]
build_tool = gradle
COMMON_BUILD_OPTS = "{GRADLE_CMD} ${GRADLE_OPTS} "
deploy_cmd = ${COMMON_BUILD_OPTS} deploy
kafka_scala_version = 2.10
kafka_scala_version_compile = 2.10.4
package_count = 2

BUILD_KAFKA_SETVERSION_OPTS = "-Pversion=${kafka_jar_version}"
BUILD_KAFKA_OPTS = "${BUILD_KAFKA_SETVERSION_OPTS}"
BUILD_KAFKA_DOC_OPTS = "${BUILD_KAFKA_OPTS} docsJar"
BUILD_KAFKA_INSTALL_OPTS = "${BUILD_KAFKA_OPTS} clean jar"
BUILD_KAFKA_EXAMPLES_INSTALL_OPTS = "${BUILD_KAFKA_OPTS} examples:jar"
BUILD_KAFKA_CONTRIB_CONSUMER_INSTALL_OPTS = "${BUILD_KAFKA_OPTS} contrib:hadoop-consumer:jar"
BUILD_KAFKA_CONTRIB_PRODUCER_INSTALL_OPTS = "${BUILD_KAFKA_OPTS} contrib:hadoop-producer:jar"
BUILD_KAFKA_CONTRIB_GANGLIA_INSTALL_OPTS = "${BUILD_KAFKA_OPTS} contrib:kafka-ganglia:jar"
BUILD_KAFKA_PERF_INSTALL_OPTS = "${BUILD_KAFKA_OPTS} perf:jar"
BUILD_KAFKA_DEPLOY_OPTS = "${BUILD_KAFKA_OPTS} releaseTarGz"
BUILD_KAFKA_TEST_OPTS = "${BUILD_KAFKA_OPTS} cleanTest test -PrepoUrl=http://${NEXUS_HOST}/nexus/content/groups/public"
BUILD_KAFKA_UPLOAD = "${BUILD_KAFKA_SETVERSION_OPTS} uploadArchivesAll"

    [[artifacts]]
        artifact_1 = core/build/distributions/kafka_${kafka_scala_version}-${kafka_jar_version}.tgz
        artifact_2 = kafka.tar.gz

    [[install_cmd]]
        cmd_0 = gradle
        cmd_1 = ./gradlew ${BUILD_KAFKA_SETVERSION_OPTS}
        cmd_2 = ./gradlew ${BUILD_KAFKA_INSTALL_OPTS}
        cmd_3 = ./gradlew ${BUILD_KAFKA_DOC_OPTS}
        cmd_4 = ./gradlew ${BUILD_KAFKA_EXAMPLES_INSTALL_OPTS}
        cmd_5 = ./gradlew ${BUILD_KAFKA_CONTRIB_GANGLIA_INSTALL_OPTS}
        cmd_6 = ./gradlew ${BUILD_KAFKA_DEPLOY_OPTS}
        cmd_7 = ./gradlew ${BUILD_KAFKA_UPLOAD}
        cmd_8 = "mv contrib/kafka-ganglia/build/libs/kafka-ganglia-${kafka_jar_version}.jar contrib/kafka-ganglia/build/libs/lib/"
        cmd_9 = "mv contrib/kafka-ganglia/build/libs/kafka-ganglia-${kafka_jar_version}-javadoc.jar contrib/kafka-ganglia/build/libs/lib/"
        cmd_10 =  "tar -zcvf kafka.tar.gz core/build/docs contrib/kafka-ganglia/build/libs/lib/ contrib/build/libs/  examples/build/libs examples/build/docs NOTICE LICENSE"

   [[test_cmd]]
        cmd_0 = gradle
        cmd_1 = ./gradlew ${BUILD_KAFKA_TEST_OPTS}

   [[text-replace]]
        REPLACE_1 = 'scalaVersion', ${kafka_scala_version_compile}, gradle.properties , key_value
        REPLACE_2 = 'version', ${kafka_jar_version}, gradle.properties , key_value
        REPLACE_3 = 'zookeeperVersion', ${zookeeper_jar_version}, gradle.properties , key_value
        REPLACE_4 = 'pigVersion', ${pig_jar_version}, gradle.properties , key_value
        REPLACE_5 = 'hadoopVersion', ${hadoop_jar_version}, gradle.properties , key_value
        REPLACE_6 = 'repoUrl', ${NEXUS_PROXY_URL}, gradle.properties , key_value
        REPLACE_7 = 'mavenUrl', ${NEXUS_REPO_URL}, gradle.properties , key_value

[knox]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN_CMD}  -Ppackage,release,analyze -DskipCheck=true -Dcheckstyle.skip=true -Drepo.id=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.repo=${NEXUS_REPO_URL}"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${knox_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS}  deploy -DskipITs -DskipTests
package = 2

    [[artifacts]]
        artifact_1 = target/${knox_jar_version}/knox-${knox_jar_version}.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} install -DskipITs -DskipTests -Dmaven.javadoc.skip=true

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} clean package

    [[xml-replace]]
    REPLACE_1 = 'gateway-version', ${knox_jar_version}, pom.xml
    REPLACE_2 = 'hadoop-version', ${hadoop_jar_version}, pom.xml

[livy]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN_CMD} ${MAVEN_TEST_OPTS} -Dtar -Pgpg -Dhadoop.version=${hadoop_jar_version} -Drepo.id=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.repository=${NEXUS_REPO_URL} -DaltDeploymentRepository=${NEXUS_DEPLOY_REPO_ID}::default::${NEXUS_REPO_URL} -DdistMgmtStagingId=${NEXUS_DEPLOY_REPO_ID} -DdistMgmtStagingUrl=${NEXUS_REPO_URL}"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${livy_jar_version} -Drepl
deploy_cmd = ${COMMON_BUILD_OPTS} deploy

    [[artifacts]]
        artifact_1 = assembly/target/livy-server-${livy_jar_version}.zip

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} install -Dmaven.javadoc.skip=true -DskipTests -Dskip -DskipITs

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} test

    [[xml-replace]]
        REPLACE_1 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'spark.version', ${spark_jar_version}, pom.xml
        REPLACE_3 = 'spark.version', ${spark2_jar_version}, repl/scala-2.11/pom.xml
        REPLACE_4 = 'spark.version', ${spark2_jar_version}, scala-api/scala-2.11/pom.xml
        REPLACE_5 = 'spark.version', ${spark2_jar_version}, integration-test/minicluster-dependencies/scala-2.11/pom.xml

[mahout]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN311_CMD} help:active-profiles -Dhadoop2.version=${hadoop_jar_version} -Dhbase.version=${hbase_jar_version} -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Dreponame=${NEXUS_DEPLOY_REPO_ID} -Drepourl=${NEXUS_REPO_URL} -Dmahout.skip.distribution=false -Psources"
setversion_cmd = ${MVN311_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${mahout_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} -DskipITs -DskipTests clean  deploy

    [[artifacts]]
        artifact_1 = distribution/target/mahout-distribution-${mahout_jar_version}.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} -DskipITs -DskipTests clean install package -Dmaven.javadoc.skip=true

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} -fae clean test -Dsite_url="file:///tmp" -DskipTests=false

    [[xml-replace]]
        REPLACE_1 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'hbase.version', ${hbase_jar_version}, pom.xml
        REPLACE_3 = 'jetty.version' , ${jetty_hwx_version} , pom.xml
        REPLACE_4 = 'mahout.skip.distribution',  'false' , distribution/pom.xml


[oozie]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN311_CMD} -fae -Dhadoop.version=${hadoop_jar_version} -Dhive.version=${hive_jar_version} -Dpig.version=${pig_jar_version} -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Dreponame=${NEXUS_DEPLOY_REPO_ID} -Drepourl=${NEXUS_REPO_URL} -DdistMgmtReleaseUrl=${NEXUS_REPO_URL} -DmavenReleaseId=${NEXUS_DEPLOY_REPO_ID} -Pgpg,hadoop-2,!hadoop-1,uber,hwx-common"
setversion_cmd = ${MVN311_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${oozie_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} deploy -DskipITs -DskipTests=true

    [[artifacts]]
        artifact_1 = distro/target/oozie-${oozie_jar_version}-distro.tar.gz
        artifact_2 = HDP-CHANGES.txt
        artifact_3 = LICENSE.txt
        artifact_4 = NOTICE.txt
        artifact_5 = README.txt
        artifact_6 = release-log.txt
        artifact_7 = source-headers.txt

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} install -DskipITs -DskipTests=true
        cmd_2 = ${COMMON_BUILD_OPTS} -DskipITs -DskipTests=true package assembly:single

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} ${MAVEN_TEST_OPTS} clean test

    [[text-replace]]
        REPLACE_1 = '<version>hadoop-2-.*</version>', '<version>hadoop-2-${oozie_jar_version}</version>', hadooplibs/hadoop-auth-2/pom.xml, regex_replace
        REPLACE_2 = '<version>hadoop-2-.*</version>', '<version>hadoop-2-${oozie_jar_version}</version>', hadooplibs/hadoop-distcp-2/pom.xml, regex_replace
        REPLACE_3 = '<version>hadoop-2-.*</version>', '<version>hadoop-2-${oozie_jar_version}</version>', hadooplibs/hadoop-utils-2/pom.xml, regex_replace

    [[xml-replace]]
        REPLACE_1 = 'hbase.version' , ${hbase_jar_version} , pom.xml
        REPLACE_2 = 'hbaselib.version' , ${hbase_jar_version}.oozie-${oozie_jar_version} , pom.xml
        REPLACE_3 = 'hcatalog.version' , ${hive_jar_version} , pom.xml
        REPLACE_4 = 'sqoop.version' , ${sqoop_jar_version} , pom.xml
        REPLACE_5 = 'pig.version' , ${pig_jar_version} , pom.xml
        REPLACE_6 = 'hive.version' , ${hive_jar_version} , pom.xml
        REPLACE_7 = 'tez.version' , ${tez_jar_version} , pom.xml
        REPLACE_8 = 'hadoop.auth.version' , ${hadoop_jar_version} , pom.xml
        REPLACE_9 = 'hadoopTwo.version' , ${hadoop_jar_version} , pom.xml
        REPLACE_10 = 'jetty.version' , ${jetty_hwx_version} , pom.xml
        REPLACE_11 = 'activeByDefault' , 'false' , pom.xml
        REPLACE_12 = 'hadoop.version' , ${hadoop_jar_version} , pom.xml
        REPLACE_13 = 'spark.version' , ${spark_jar_version} , pom.xml

[phoenix]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN_CMD} -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Dreponame=${NEXUS_DEPLOY_REPO_ID} -Drepourl=${NEXUS_REPO_URL} -Drepo.maven.org=${NEXUS_PROXY_URL}"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${phoenix_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} clean package deploy -Pgpg -DskipITs -DskipTests

    [[artifacts]]
        artifact_1 = phoenix-assembly/target/phoenix-${phoenix_jar_version}.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} clean install package -DskipITs -DskipTests -Dmaven.javadoc.skip=true

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} ${MAVEN_TEST_OPTS} clean verify

    [[xml-replace]]
        REPLACE_1 = 'flume.version', ${flume_jar_version}, pom.xml
        REPLACE_2 = 'hadoop-two.version', ${hadoop_jar_version}, pom.xml
        REPLACE_3 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_4 = 'hbase.version', ${hbase_jar_version}, pom.xml
        REPLACE_5 = 'pig.version', ${pig_jar_version}, pom.xml
        REPLACE_6 = 'jetty.version' , ${jetty_hwx_version}, pom.xml
        REPLACE_7 = 'avatica.version', ${avatica_jar_version}, pom.xml
        REPLACE_8 = 'calcite.version', ${calcite_jar_version}, pom.xml
        REPLACE_9 = 'hive.version', ${hive_jar_version}, pom.xml

[pig]
build_tool = ant
COMMON_BUILD_OPTS = "${ANT_CMD} -Djavac.version=1.7 -Dversion=${pig_jar_version} -Dzookeeper.version=${zookeeper_jar_version} -Dhive.version=${hive_jar_version} -Dtez.version=${tez_jar_version} -Daccumulo15.version=${accumulo_jar_version} -Dhbaseversion=95 -Dhbase95.version=${hbase_jar_version} -Dhadoop-common.version=${hadoop_jar_version} -Dhadoop-hdfs.version=${hadoop_jar_version} -Dhadoop-mapreduce.version=${hadoop_jar_version} -Dtest.junit.output.format=xml -Dforrest.home=${FORREST_HOME} -Dhadoopversion=23 -Dmvnrepo=${NEXUS_PROXY_URL} -Drepo.apache.snapshots=${NEXUS_PROXY_URL} -Drepo.jboss.org=${NEXUS_PROXY_URL}"
deploy_cmd = ${COMMON_BUILD_OPTS} -f nexus-build.xml -Dstaging_repo_id=${NEXUS_DEPLOY_REPO_ID} -Dasfstagingrepo=${NEXUS_REPO_URL} stage
BUILD_PIG_COMPILE_JAR="${COMMON_BUILD_OPTS} very-clean jar pigunit-jar smoketests-jar compile-test"

    [[artifacts]]
        artifact_1 = build/pig-${pig_jar_version}.tar.gz
        artifact_2 = pig.tar.gz
        artifact_3 = build/pig-${pig_jar_version}-smoketests.jar

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} mvn-install
        cmd_2 = ${COMMON_BUILD_OPTS} very-clean jar pigunit-jar smoketests-jar compile-test
        cmd_3 = ${COMMON_BUILD_OPTS} -buildfile contrib/piggybank/java/build.xml clean jar
        cmd_4 = ${COMMON_BUILD_OPTS} -Dant-task.version=2.1.3 tar
        cmd_5 = "tar -cz --exclude-vcs --transform 's,^build\/tar\/pig-${pig_jar_version}\/,pig/,' -f pig.tar.gz build/tar/pig-${pig_jar_version}"

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} -Dant-task.version=2.1.3 test-core-mrtez

[ranger]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN333_CMD} -DskipCheck=true -Dcheckstyle.skip=true -DdistMgmtStagingId=${NEXUS_DEPLOY_REPO_ID} -DdistMgmtStagingUrl=${NEXUS_REPO_URL}"
setversion_cmd = ${MVN333_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${ranger_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} package assembly:assembly deploy -Pgpg -DskipITs -DskipTests -Dmaven.javadoc.skip=true
PATH = "${PYTHON27_PATH}:${PATH}"

    [[artifacts]]
        artifact_1 = target/ranger-${ranger_jar_version}-admin.tar.gz
        artifact_2 = target/ranger-${ranger_jar_version}-hbase-plugin.tar.gz
        artifact_3 = target/ranger-${ranger_jar_version}-hdfs-plugin.tar.gz
        artifact_4 = target/ranger-${ranger_jar_version}-hive-plugin.tar.gz
        artifact_5 = target/ranger-${ranger_jar_version}-kafka-plugin.tar.gz
        artifact_6 = target/ranger-${ranger_jar_version}-kms.tar.gz
        artifact_7 = target/ranger-${ranger_jar_version}-knox-plugin.tar.gz
        artifact_8 = target/ranger-${ranger_jar_version}-migration-util.tar.gz
        artifact_9 = target/ranger-${ranger_jar_version}-ranger-tools.tar.gz
        artifact_10 = target/ranger-${ranger_jar_version}-solr-plugin.tar.gz
        artifact_11 = target/ranger-${ranger_jar_version}-storm-plugin.tar.gz
        artifact_12 = target/ranger-${ranger_jar_version}-tagsync.tar.gz
        artifact_13 = target/ranger-${ranger_jar_version}-usersync.tar.gz
        artifact_14 = target/ranger-${ranger_jar_version}-yarn-plugin.tar.gz
        artifact_15 = target/ranger-${ranger_jar_version}-src.tar.gz
        artifact_16 = target/ranger-${ranger_jar_version}-atlas-plugin.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} package assembly:assembly install -Pgpg -DskipITs -DskipTests -Dmaven.javadoc.skip=true
        
    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} test ${MAVEN_TEST_OPTS}

    [[xml-replace]]
        REPLACE_1 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'hadoop-auth.version', ${hadoop_jar_version}, pom.xml
        REPLACE_3 = 'hadoop-common.version', ${hadoop_jar_version}, pom.xml
        REPLACE_4 = 'hbase.version', ${hbase_jar_version}, pom.xml
        REPLACE_5 = 'hive.version', ${hive_jar_version}, pom.xml
        REPLACE_6 = 'knox.gateway.version', ${knox_jar_version}, pom.xml
        REPLACE_7 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml
        REPLACE_8 = 'tez.version', ${tez_jar_version}, pom.xml
        REPLACE_9 = 'calcite.version', ${calcite_jar_version}, pom.xml
        REPLACE_10 = 'kafka.version', ${kafka_jar_version}, pom.xml
        REPLACE_11 = 'storm.version', ${storm_jar_version}, pom.xml
        REPLACE_12 = 'mortbay.jetty.version', ${jetty_hwx_version}, pom.xml

# TODO(Sriharsha) special handling - slider app packages
[slider]
build_tool = maven
COMMON_BUILD_OPTS = ${MVN_CMD} -Phwx-common
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${slider_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} -Psign -Pgpg deploy -DdistMgmtStagingId=${NEXUS_DEPLOY_REPO_ID} -DdistMgmtStagingUrl=${NEXUS_REPO_URL} -DskipITs -DskipTests
slider_build_opts_storm = ${MVN_CMD} package -Pstorm-app-package -Dpkg.version=${storm_jar_version} -Dpkg.name=apache-storm-${storm_jar_version}.tar.gz -Dstorm.version=${storm_jar_version}
slider_build_opts_accumulo = ${MVN_CMD} package -Phdp -Paccumulo-app-package -Dpkg.version=${accumulo_jar_version} -Dpkg.name=accumulo-${accumulo_jar_version}-bin.tar.gz -Daccumulo.version=${accumulo_jar_version} -Dhadoop.version=${hadoop_jar_version}
slider_build_opts_hbase = ${MVN_CMD} package -Phbase-app-package -Dpkg.version=${hbase_jar_version} -Dpkg.name=hbase-${hbase_jar_version}.tar.gz -Dhbase.version=${hbase_jar_version} -Dhadoop.version=${hadoop_jar_version}
package_count = 2

    [[artifacts]]
        artifact_1 = slider-assembly/target/slider-${slider_jar_version}-all.tar.gz

    [[install_cmd]]
        cmd_1 = "${COMMON_BUILD_OPTS} install -DskipITs -DskipTests"

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} test -Dsurefire.timeout=9600 ${MAVEN_TEST_OPTS}

    [[xml-replace]]
        REPLACE_1 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml
        REPLACE_3 = 'hbase.version', ${hbase_jar_version}, pom.xml
        REPLACE_4 = 'accumulo.version', ${accumulo_jar_version}, pom.xml

[slider-app-packages]
build_tool = maven
COMMON_BUILD_OPTS = ${MVN_CMD} -Phwx-common
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${slider_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} -Psign -Pgpg deploy -DdistMgmtStagingId=${NEXUS_DEPLOY_REPO_ID} -DdistMgmtStagingUrl=${NEXUS_REPO_URL} -DskipITs -DskipTests
test_cmd = ${COMMON_BUILD_OPTS} test -Dmaven.test.error.ignore=true  -Dsurefire.timeout=9600  -Dmaven.test.failure.ignore=true
slider_build_opts_storm = ${COMMON_BUILD_OPTS} package -Pstorm-app-package -Dpkg.version=${storm_jar_version} -Dpkg.name=apache-storm-${storm_jar_version}.tar.gz -Dstorm.version=${storm_jar_version}
slider_build_opts_accumulo = ${COMMON_BUILD_OPTS} package -Phdp -Paccumulo-app-package -Dpkg.version=${accumulo_jar_version} -Dpkg.name=accumulo-${accumulo_jar_version}-bin.tar.gz -Daccumulo.version=${accumulo_jar_version} -Dhadoop.version=${hadoop_jar_version}
slider_build_opts_hbase = ${COMMON_BUILD_OPTS} package -Phbase-app-package -Dpkg.version=${hbase_jar_version} -Dpkg.name=hbase-${hbase_jar_version}.tar.gz -Dhbase.version=${hbase_jar_version} -Dhadoop.version=${hadoop_jar_version}

    [[artifacts]]
        artifact_1 = app-packages/command-logger/slider-pkg/target/command-logger-slider-package.zip
        artifact_2 = app-packages/storm/target/slider-storm-app-package-${storm_jar_version}.zip
        artifact_3 = app-packages/hbase/target/slider-hbase-app-package-${hbase_jar_version}.zip
        artifact_4 = app-packages/accumulo/target/slider-accumulo-app-package-${accumulo_jar_version}.zip

    [[install_cmd]]
        cmd_1 = "${slider_build_opts_storm} install -DskipITs -DskipTests -Dpkg.src=${TAR_DIR}" , app-packages
        cmd_2 = "${slider_build_opts_accumulo} install -DskipITs -DskipTests -Dpkg.src=${TAR_DIR}" , app-packages
        cmd_3 = "${slider_build_opts_hbase} install -DskipITs -DskipTests -Dpkg.src=${TAR_DIR}" , app-packages
        cmd_4 = "${COMMON_BUILD_OPTS} install" , app-packages/command-logger/application-pkg
        cmd_5 = "${COMMON_BUILD_OPTS} install" , app-packages/command-logger/slider-pkg

    [[xml-replace]]
        REPLACE_1 = 'accumulo.version', ${accumulo_jar_version}, pom.xml
        REPLACE_2 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_3 = 'hbase.version', ${hbase_jar_version}, pom.xml
        REPLACE_4 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml

[spark]
build_tool = maven
BUILD_SPARK_SETVERSION_OPTS = ${MVN333_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${spark_jar_version} -DgenerateBackupPoms=false
COMMON_BUILD_OPTS = "${SOURCE_ROOT}/spark/build/mvn -T C1 -Phive -Phive-thriftserver -Pyarn -Phadoop-2.7 -Phbase-provided -Dhbase.profile=hadoop2 -Drepo.id=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.repo=${NEXUS_REPO_URL} -Phwx-common -Pbigtop-dist -Dsurefire.timeout=9600 ${MAVEN_TEST_OPTS} -Psparkr -Dskip"
setversion_cmd = ${MVN333_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${spark_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} package deploy -DskipTest -Dskip
package_count = 5

   [[PASSTHROUGH_ENV]]
        HADOOP_VERSION=${hadoop_jar_version}
        SPARK_VERSION=${spark_jar_version}

    [[artifacts]]
        artifact_1 = assembly/target/spark-assembly_2.10-${spark_jar_version}-dist.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} install -DskipTests -Dskip=true

    [[test_cmd]]
        cmd_1  = ${COMMON_BUILD_OPTS} -fae test -Phwx-common -Psparkr

    [[text-replace]]
        REPLACE_1 = '<hive.version>.*</hive.version>', '<hive.version>1.2.1.spark.hdp</hive.version>', pom.xml, regex_replace

    [[xml-replace]]
        REPLACE_1 = 'flume.version', ${flume_jar_version}, pom.xml
        REPLACE_2 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_3 = 'hbase.version', ${hbase_jar_version}, pom.xml
        REPLACE_4 = 'protobuf.version', ${protobuf_version}, pom.xml
        REPLACE_5 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml
        REPLACE_6 = 'kafka.version', ${kafka_jar_version}, pom.xml

[spark2]
build_tool = maven
BUILD_SPARK_SETVERSION_OPTS = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${spark2_jar_version} -DgenerateBackupPoms=false
COMMON_BUILD_OPTS = "-Phive -Phive-thriftserver -Pyarn -Phadoop-2.7 -Phwx-common -Dhbase.profile=hadoop2 -Drepo.id=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.repo=${NEXUS_REPO_URL} -Pbigtop-dist -Dsurefire.timeout=9600 ${MAVEN_TEST_OPTS} -Psparkr -Dskip"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${spark2_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} package deploy -DskipTests -Dskip
package_count = 5

   [[PASSTHROUGH_ENV]]
        HADOOP_VERSION=${hadoop_jar_version}
        SPARK2_VERSION=${spark2_jar_version}
    [[artifacts]]
        artifact_1 = spark-${spark2_jar_version}-bin-${hadoop_jar_version}.tgz

    [[install_cmd]]
        cmd_1 = dev/make-distribution.sh --tgz ${COMMON_BUILD_OPTS} -Dskip=true

    [[test_cmd]]
        cmd_1 = ${MVN_CMD} ${COMMON_BUILD_OPTS} -fae test

    [[xml-replace]]
        REPLACE_1 = 'flume.version', ${flume_jar_version}, pom.xml
        REPLACE_2 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_3 = 'hbase.version', ${hbase_jar_version}, pom.xml
        REPLACE_4 = 'protobuf.version', ${protobuf_version}, pom.xml
        REPLACE_5 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml
        REPLACE_6 = 'kafka.version', ${kafka_jar_version}, pom.xml

[spark-llap]
build_tool = sbt

    [[artifacts]]
        artifact_1 = target/spark-llap-assembly-${spark-llap_jar_version}.jar

    [[install_cmd]]
        cmd_1 = ./build/sbt compile -DskipTests -Dversion=${spark-llap_jar_version}  -Dhadoop.version=${hadoop_jar_version} -Dhive.version=${hive2_jar_version} -Dtez.version=${tez_hive2_jar_version} -Drepourl=${NEXUS_PROXY_URL}
        cmd_2 = ./build/sbt  assembly -DskipTests -Dversion=${spark-llap_jar_version}  -Dhadoop.version=${hadoop_jar_version} -Dhive.version=${hive2_jar_version} -Dtez.version=${tez_hive2_jar_version} -Drepourl=${NEXUS_PROXY_URL}
        cmd_3 = ./build/sbt  publishM2 -DskipTests -Dversion=${spark-llap_jar_version}  -Dhadoop.version=${hadoop_jar_version} -Dhive.version=${hive2_jar_version} -Dtez.version=${tez_hive2_jar_version} -Drepourl=${NEXUS_PROXY_URL}

    [[text-replace]]
        REPLACE_1 = 'version :=.*', 'version := "${spark-llap_jar_version}"', build.sbt, regex_replace
[sqoop]
build_tool = ant
COMMON_BUILD_OPTS = "${ANT_CMD} -Dmvn.version=2.1.3 -Dhadoopversion=200 -Dhbaseprofile=95 -Dhcatprofile=13 -Dhadoop.version=${hadoop_jar_version} -Dhbase95.version=${hbase_jar_version} -Dhcatalog.version=${hive_jar_version} -Dzookeeper.version=${zookeeper_jar_version} -Daccumulo.version=${accumulo_jar_version} -Dversion=${sqoop_jar_version} -Dhadoop.version.full=${hadoop_jar_version} -Dprev.git.hash=HEAD -Dtest.junit.output.format=xml -Dslf4j.version=1.6.1 -Dmvn.repo=${NEXUS_DEPLOY_REPO_ID} -Dmvn.repo.id=${NEXUS_DEPLOY_REPO_ID} -Dmvn.deploy.url=${NEXUS_REPO_URL} -Drepo.maven.org=${NEXUS_PROXY_URL} -Dsnapshot.apache.org=${NEXUS_PROXY_URL} -Dstaging.cloudera.com=${NEXUS_PROXY_URL} -Dreleases.cloudera.com=${NEXUS_PROXY_URL}"
deploy_cmd = ${COMMON_BUILD_OPTS} clean mvn-install mvn-deploy tar
package_count = 3

    [[artifacts]]
        artifact_1 = build/sqoop-${sqoop_jar_version}.bin__hadoop-${hadoop_jar_version}.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} clean mvn-install tar -Dmaven.javadoc.skip=true

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} clean test tar -Dmvn.version=2.1.3


[storm]
build_tool = maven
storm_alternate_name = apache-storm
COMMON_BUILD_OPTS = "${MVN_CMD} -Dhive.version=${hive_jar_version} -Dzookeeper.version=${zookeeper_jar_version} -Dhadoop.version=${hadoop_jar_version} -Dhbase.version=${hbase_jar_version} -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Dreponame=${NEXUS_DEPLOY_REPO_ID} -Drepourl=${NEXUS_REPO_URL} -Drepo.maven.org=${NEXUS_PROXY_URL}"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${storm_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} clean package deploy -Pdist -Pgpg -Psign -DskipITs -DskipTests
BUILD_STORM_PACKAGING_OPTS =${COMMON_BUILD_OPTS} package -Pdist -Pgpg -DskipITs -DskipTests
package_count = 3

    [[artifacts]]
        artifact_1 = storm-dist/binary/target/${storm_alternate_name}-${storm_jar_version}.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} clean install -DskipITs -DskipTests -Pdist -Psign -Pgpg -Dmaven.javadoc.skip=true
        cmd_2 = ${COMMON_BUILD_OPTS} -DskipITs -DskipTests -Pnative -Dworker-launcher.conf.dir=/etc/storm/conf clean package
        cmd_3 = ${COMMON_BUILD_OPTS} package -Pdist -Pgpg -DskipITs -DskipTests , storm-dist/binary
        cmd_4 = ${COMMON_BUILD_OPTS} package -Pdist -Pgpg -DskipITs -DskipTests , storm-dist/source

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} clean package -DskipTests
        cmd_2 = ${COMMON_BUILD_OPTS} test ${MAVEN_TEST_OPTS}

    [[text-replace]]
        REPLACE_1 = '2.4.0', ${hadoop_jar_version}, pom.xml , key_value

    [[xml-replace]]
        REPLACE_1 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'hbase.version', ${hbase_jar_version}, pom.xml
        REPLACE_3 = 'hive.version', ${hive_jar_version}, pom.xml
        REPLACE_4 = 'kafka.version', ${kafka_jar_version}, pom.xml
        REPLACE_5 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml
        REPLACE_6 = 'hdfs.version', ${hadoop_jar_version}, pom.xml
        REPLACE_7 = 'sigar.download.url', 'http://s3.amazonaws.com/dev.hortonworks.com/ARTIFACTS/hyperic-sigar-1.6.4.zip', external/storm-metrics/pom.xml

[teradata_connector]
tdchprofile = 2
hadoopprofile = 200
sqoopclassifier=hadoop200
HortonworksConnectorForTeradataversion = 1.5.0
terajdbc4version = 15.10.00.17
TeradataConnectorForHadoopversion = 1.5.0
TeradataConnectorForHadoopversion2 = ${TeradataConnectorForHadoopversion}-hadoop${tdchprofile}
TeradataConnectorForHadoop_file=${TeradataConnectorForHadoop_name}-${TeradataConnectorForHadoopversion2}.jar
tdgssconfigversion = 15.10.00.17
TeradataConnectorForHadoop_name = "teradata-connector"
TeradataConnectorForHadoop_groupId = "com.teradata.hadoop"
TeradataConnectorForHadoop_mvn_install_argument = "-DgroupId=${TeradataConnectorForHadoop_groupId} -DartifactId=${TeradataConnectorForHadoop_name} -Dversion=${TeradataConnectorForHadoopversion2} -Dpackaging=jar -DgeneratePom=true -Dfile=${TeradataConnectorForHadoop_file}"
terajdbc4_name = "terajdbc4"
terajdbc4_groupId = "com.teradata"
terajdbc4_mvn_install_argument = "-DgroupId=${terajdbc4_groupId} -DartifactId=${terajdbc4_name} -Dversion=${terajdbc4version} -Dpackaging=jar -DgeneratePom=true -Dfile=${terajdbc4_name}.jar"
tdgssconfig_name = "tdgssconfig"
tdgssconfig_groupId = "com.teradata"
tdgssconfig_mvn_install_argument = "-DgroupId=${tdgssconfig_groupId} -DartifactId=${tdgssconfig_name} -Dversion=${tdgssconfigversion} -Dpackaging=jar -DgeneratePom=true -Dfile=${tdgssconfig_name}.jar"
hadoop1version = 1.1.2.22
mvn_argument_withouttest = "-U -DskipTests -Dhadoop.1.version=${hadoop1version} -Dhadoop.2.version=${hadoop_jar_version} -Dhadoop.profile=${hadoopprofile} -Dtdch.profile=${tdchprofile} -Dteradata.jdbc.version=${terajdbc4version} -Dsqoop.version=${sqoop_jar_version} -Dsqooptest.version=${sqoop_jar_version} -Dhcatalog.version=${hive_jar_version} -Dhive.version=${hive_jar_version} -Dteradata-connector.base.version=${TeradataConnectorForHadoopversion} -Dinternal.maven.repo=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.reposoitory=${NEXUS_REPO_URL}"

mvn_argument_withtest="-U -Dhadoop.1.version=${hadoop1version} -Dhadoop.2.version=${hadoop_jar_version} -Dhadoop.profile=${hadoopprofile} -Dtdch.profile=${tdchprofile} -Dteradata.jdbc.version=${terajdbc4version} -Dsqoop.version=${sqoop_jar_version} -Dsqooptest.version=${sqoop_jar_version} -Dhcatalog.version=${hive_jar_version} -Dhive.version=${hive_jar_version} -Dteradata-connector.base.version=${TeradataConnectorForHadoopversion} -Dinternal.maven.repo=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.reposoitory=${NEXUS_REPO_URL}"
mvn_argument = ${mvn_argument_withouttest}

    [[artifacts]]
        artifact_1 = target/hdp-connector-for-teradata-${teradata_connector_jar_version}-distro.tar.gz

    [[install_cmd]]
        cmd_0 = "find . -name 'pom.xml' -type f -exec perl -pi.bak -e 's/^(.*sqoop.classifier.*$)/<!-- \1 -->/' {} \;"
        cmd_1 = ${MVN_CMD} install:install-file ${TeradataConnectorForHadoop_mvn_install_argument}, libext
        cmd_2 = ${MVN_CMD} install:install-file ${terajdbc4_mvn_install_argument} , libext
        cmd_3 = ${MVN_CMD} install:install-file ${tdgssconfig_mvn_install_argument} , libext
        cmd_4 = ${MVN_CMD} -e org.codehaus.mojo:versions-maven-plugin:1.3.1:set  -DnewVersion=${teradata_connector_jar_version}
        cmd_5 = ${MVN_CMD} clean package -X -e ${mvn_argument}
        cmd_6 = ${MVN_CMD} clean package ${mvn_argument} assembly:assembly

    [[replace_cmd]]
        REPLACE_1 = 'hadoop.2.version',  ${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'sqoop.version',  ${sqoop_jar_version}, pom.xml
        REPLACE_3 = 'hcatalog.version',  ${hive_jar_version}, pom.xml

[tez]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN_CMD} clean ${MAVEN_TEST_OPTS} -Dtar -Pgpg -Phwx-common -Psources -Dhadoop.version=${hadoop_jar_version} -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Dreponame=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.repository=${NEXUS_REPO_URL} -DdistMgmtStagingId=${NEXUS_DEPLOY_REPO_ID} -DdistMgmtStagingUrl=${NEXUS_REPO_URL}"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${tez_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} deploy
package_count = 2

    [[artifacts]]
        artifact_1 = tez-dist/target/tez-${tez_jar_version}-minimal.tar.gz
        artifact_2 = tez-dist/target/tez-${tez_jar_version}.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} install -DskipTests

    [[test_cmd]]
	cmd_1 = npm set strict-ssl false
        cmd_2 = ${COMMON_BUILD_OPTS} test -Pclover

    [[xml-replace]]
        REPLACE_1 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml
        REPLACE_3 = 'jetty.version', ${jetty_hwx_version} , pom.xml

[tez_hive2]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN_CMD} ${MAVEN_TEST_OPTS} -Dtar -Pgpg -Psources -Paws -Pazure -Phwx-common -Dhadoop.version=${hadoop_jar_version} -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Dreponame=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.repository=${NEXUS_REPO_URL} -DdistMgmtStagingId=${NEXUS_DEPLOY_REPO_ID} -DdistMgmtStagingUrl=${NEXUS_REPO_URL}"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${tez_hive2_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} deploy
package_count = 2

    [[artifacts]]
        artifact_1 = tez-dist/target/tez-${tez_hive2_jar_version}-minimal.tar.gz
        artifact_2 = tez-dist/target/tez-${tez_hive2_jar_version}.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} clean install -DskipTests

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} clean test

    [[xml-replace]]
        REPLACE_1 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml
        REPLACE_3 = 'jetty.version', ${jetty_hwx_version} , pom.xml

# TODO (sriharsha) figure out spark version from pom.xml , BUG-58027 cached apache archive tar to s3.
# https://github.com/hortonworks/build-support/commit/6a258920f96f89aa7bec590734db69cf878c42a9
[zeppelin]
build_tool = maven
spark_pkg_version = 1.4.1
COMMON_BUILD_OPTS = ${MVN_CMD} -Divy.home=${HOME}/.ivy2 -Dsbt.ivy.home=${HOME}/.ivy2 -Duser.home=${HOME} -Drepo.maven.org=${NEXUS_REPO_URL} -DaltDeploymentRepository=${NEXUS_DEPLOY_REPO_ID}::default::${NEXUS_REPO_URL} -Dreactor.repo='file://${HOME}/.m2/repository' -Pspark-1.5 -Dspark.version=${spark_jar_version} -Phadoop-2.6 -Dhadoop.version=${hadoop_jar_version} -Pyarn -Pbuild-distr -Drat.skip=True -Dspark.download.url=http://public-repo-1.hortonworks.com/ARTIFACTS/dist/spark/spark-${spark_pkg_version}/spark-${spark_pkg_version}.tgz -Dspark.bin.download.url=http://public-repo-1.hortonworks.com/ARTIFACTS/dist/spark/spark-${spark_pkg_version}/spark-${spark_pkg_version}-bin-without-hadoop.tgz
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${zeppelin_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} deploy -DskipTests

    [[artifacts]]
        artifact_1 = zeppelin-distribution/target/zeppelin-${zeppelin_jar_version}.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} install -DskipTests

    [[xml-replace]]
        REPLACE_1 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'hbase.hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_3 = 'hadoop-common.version', ${hadoop_jar_version}, pom.xml
        REPLACE_4 = 'hbase.version', ${hbase_jar_version}, pom.xml
        REPLACE_5 = 'hbase.hbase.version', ${hbase_jar_version}, pom.xml
        REPLACE_6 = 'spark.version', ${spark_jar_version}, pom.xml
        REPLACE_7 = 'protobuf.version', ${protobuf_version}, pom.xml
        REPLACE_8 = 'zookeeper.version' , ${zookeeper_jar_version} , pom.xml

[zookeeper]
build_tool = ant
# TODO (Sriharsha) removed -Djavac.args=\'-Xlint -Xmaxwarns 1000\' due to quotes issue
COMMON_BUILD_OPTS ="${ANT_CMD}  -Dversion=${zookeeper_jar_version} -Dcppunit.m4=/usr/share/aclocal -Dtest.junit.output.format=xml  -DAM_PATH_CPPUNIT=/usr/lib64 -Drepo.maven.org=${NEXUS_PROXY_URL} -Drepo.jboss.org=${NEXUS_PROXY_URL} -Divy.url='http://central.maven.org/maven2/org/apache/ivy/ivy' -Dmvnrepo=${NEXUS_PROXY_URL}"
deploy_cmd = "${COMMON_BUILD_OPTS} -f nexus-build.xml -Dstaging_repo_id=${NEXUS_DEPLOY_REPO_ID} -Dstaging_repo_url=${NEXUS_REPO_URL} stage"
package_count = 3

    [[artifacts]]
        artifact_1 = build/zookeeper-${zookeeper_jar_version}.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} mvn-install
        cmd_2 = ${COMMON_BUILD_OPTS} -f build.xml tar

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} clean test -Djunit.default.timeout=5000
