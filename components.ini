#[component-name]
# HDP_VERSION -> Distro.ini
# git_url -> hdp-base.json
# branch -> hdp-base.json
# comp_version -> hdp-base.json
# BUILD_NUMBER -> jenkins Env
# package_count. this file -> overriden by platfom_components.txt
# build_tool -> this file
# install.cmd -> this file
# deploy.cmd  -> this file
# UnitTest Command -> this file
# depends_on -> hdp-base.json
# text-replace, xml-replace, xpath-replace - for replacing versions in component code

[accumulo]
build_tool = maven
# Maven build defaults to building with -Dhadoop.profile=3 so we do not need to explicit set that
COMMON_BUILD_OPTS = "${MVN_CMD} -Dfindbugs.skip -Dcheckstyle.skip -Pdocs,assemble -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Drepourl=${NEXUS_REPO_URL} -Dreponame=${NEXUS_DEPLOY_REPO_ID} ${MAVEN_TEST_OPTS}"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${accumulo_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} -DskipTests deploy
coverage_tool = cobertura

    [[artifacts]]
        artifact_1 = assemble/target/accumulo-${accumulo_jar_version}-bin.tar.gz
        artifact_2 = server/native/target/accumulo-native-${accumulo_jar_version}/accumulo-native-${accumulo_jar_version}/libaccumulo.so
        artifact_3 = test.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} -DskipTests install -Dmaven.javadoc.skip=true
        cmd_2 = "tar --exclude-vcs -zcf test.tar.gz test"

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} clean package -Dsurefire.timeout=2400

    [[test_coverage_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} clean cobertura:cobertura -Dsurefire.timeout=2400

    [[fortify_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} -DskipTests install -Dmaven.javadoc.skip=true
        cmd_2 = ${COMMON_BUILD_OPTS} -DskipTests -Dmaven.javadoc.skip=true ${FORTIFY_ARGS} -Dfortify.sca.buildId=accumulo-${accumulo_jar_version} ${FORTIFY_CLEAN_CMD}
        cmd_3 = ${COMMON_BUILD_OPTS} -DskipTests -Dmaven.javadoc.skip=true ${FORTIFY_ARGS} -Dfortify.sca.buildId=accumulo-${accumulo_jar_version} -Dfortify.sca.verbose=true -Dfortify.sca.translateLogfile=translate.log -Dfortify.sca.debug=true ${FORTIFY_TRANSLATE_CMD}
        cmd_4 = sourceanalyzer -b accumulo-${accumulo_jar_version} ${FORTIFY_SCAN_LARGE_MEMORY} -scan -f accumulo-${accumulo_jar_version}.fpr


    [[xml-replace]]
        REPLACE_1 = 'hadoop.version' , ${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'zookeeper.version' , ${zookeeper_jar_version}, pom.xml

# TODO (sriharsha) figure out hbase, solr version from pom.xml , BUG-58027 cached apache archive tar to s3.
# https://github.com/hortonworks/build-support/commit/6a258920f96f89aa7bec590734db69cf878c42a9
[atlas]
build_tool = maven
atlas_alternate_name = apache-atlas
hbase_pkg_version = 1.1.2
solr_pkg_version = 5.1.0
COMMON_BUILD_OPTS = "${MVN352_CMD} -Dfindbugs.skip=true -Pgpg -DskipDocs=true -Dhadoop.version=${hadoop_jar_version} -Dzookeeper.version=${zookeeper_jar_version} -Dinternal.maven.repository=${NEXUS_REPO_URL} -DStagingId=${NEXUS_DEPLOY_REPO_ID} -DStagingUrl=${NEXUS_REPO_URL} -Dhbase.tar=http://public-repo-1.hortonworks.com/ARTIFACTS/dist/hbase/${hbase_pkg_version}/hbase-${hbase_pkg_version}-bin.tar.gz -Dsolr.tar=http://public-repo-1.hortonworks.com/ARTIFACTS/dist/lucene/solr/${solr_pkg_version}/solr-${solr_pkg_version}.tgz"
setversion_cmd = ${MVN352_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${atlas_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} -Pdist -DskipTests -DskipITs deploy assembly:assembly
package_count = 3
coverage_tool = cobertura

    [[artifacts]]
        artifact_1 = distro/target/${atlas_alternate_name}-${atlas_jar_version}-bin.tar.gz
        artifact_2 = distro/target/${atlas_alternate_name}-${atlas_jar_version}-hbase-hook.tar.gz
        artifact_3 = distro/target/${atlas_alternate_name}-${atlas_jar_version}-storm-hook.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} -Pdist -DskipTests -DskipITs install

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} --fail-at-end -Dsurefire.timeout=1200 -DfailIfNoTests=false test

    [[test_coverage_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} --fail-at-end -Dsurefire.timeout=1200 -DfailIfNoTests=false cobertura:cobertura

    [[fortify_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} -Pdist -DskipTests -DskipITs install
        cmd_2 = ${COMMON_BUILD_OPTS} -Pdist -DskipTests -DskipITs ${FORTIFY_ARGS} -Dfortify.sca.buildId=${atlas_alternate_name}-${atlas_jar_version} ${FORTIFY_CLEAN_CMD}
        cmd_3 = ${COMMON_BUILD_OPTS} -Pdist -DskipTests -DskipITs ${FORTIFY_ARGS} -Dfortify.sca.buildId=${atlas_alternate_name}-${atlas_jar_version} ${FORTIFY_TRANSLATE_CMD}
        cmd_4 = sourceanalyzer -b ${atlas_alternate_name}-${atlas_jar_version} ${FORTIFY_SCAN_MEMORY} -scan -f ${atlas_alternate_name}-${atlas_jar_version}.fpr

    [[text-replace]]
        REPLACE_1 = '0.8-incubating-SNAPSHOT', ${atlas_jar_version}, build-tools/pom.xml , regex_replace

    [[xml-replace]]
        REPLACE_1 = 'hadoop.version' , ${hadoop_jar_version} , pom.xml
        REPLACE_2 = 'hive.version' , ${hive_jar_version} , pom.xml
        REPLACE_3 = 'calcite.version', ${calcite_jar_version} , pom.xml
        REPLACE_4 = 'zookeeper.version' , ${zookeeper_jar_version} , pom.xml
        REPLACE_5 = 'hbase.version' , ${hbase_jar_version} , pom.xml
        REPLACE_6 = 'kafka.version', ${kafka_jar_version} , pom.xml


[avatica]
build_tool = maven
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${avatica_jar_version}
deploy_cmd = "${MVN_CMD} deploy -Drepo.id=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.repo=${NEXUS_REPO_URL} -DskipITs -DskipTests"
no_package = True

    [[install_cmd]]
        cmd_1 = ${MVN_CMD} install package -DskipITs -DskipTests

    [[test_cmd]]
        cmd_1 = ${MVN_CMD} test

[arrow]
build_tool = maven
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${arrow_jar_version}, java
deploy_cmd = "${MVN_CMD} deploy -Drepo.id=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.repo=${NEXUS_REPO_URL} -DskipITs -DskipTests", java
no_package = True

    [[install_cmd]]
        cmd_1 = ${MVN_CMD} install, java

    [[xml-replace]]
        REPLACE_1 = 'dep.hadoop.version' , ${hadoop_jar_version} , java/pom.xml

[bigtop-tomcat]
build_tool = ant
    [[install_cmd]]
        cmd_0 = mkdir -p ${TAR_DIR}/bigtop-tomcat , ${BASE_DIR}
        cmd_1 = "wget -O ${TAR_DIR}/bigtop-tomcat/apache-tomcat-${TOMCAT_VERSION}.tar.gz http://dev.hortonworks.com.s3.amazonaws.com/ARTIFACTS/dist/tomcat/tomcat-6/v${TOMCAT_VERSION}/bin/apache-tomcat-${TOMCAT_VERSION}.tar.gz", ${BASE_DIR}

[bigtop-jsvc]
build_tool = ant
    [[install_cmd]]
        cmd_0 = mkdir -p ${TAR_DIR}/bigtop-jsvc , ${BASE_DIR}
        cmd_1 = "wget -O ${TAR_DIR}/bigtop-jsvc/commons-daemon-${JSVC_VERSION}.tar.gz http://dev.hortonworks.com.s3.amazonaws.com/ARTIFACTS/dist/commons/daemon/source/commons-daemon-${JSVC_VERSION}-native-src.tar.gz" , ${BASE_DIR}


[calcite]
build_tool = maven
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${calcite_jar_version}
deploy_cmd = "${MVN_CMD} deploy -Drepo.id=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.repo=${NEXUS_REPO_URL} -DskipITs -DskipTests"
no_package = True

    [[install_cmd]]
        cmd_1 = ${MVN_CMD} install package -DskipITs -DskipTests

    [[test_cmd]]
        cmd_1 = ${MVN_CMD} -DfailIfNoTests=false -Dmaven.test.failure.ignore=true test

    [[fortify_cmd]]
        cmd_1 = ${MVN_CMD} -DskipITs -DskipTests install
        cmd_2 = ${MVN_CMD} -DskipITs -DskipTests ${FORTIFY_ARGS} -Dfortify.sca.buildId=calcite-${calcite_jar_version} ${FORTIFY_CLEAN_CMD}
        cmd_3 = ${MVN_CMD} -DskipITs -DskipTests ${FORTIFY_ARGS} -Dfortify.sca.buildId=calcite-${calcite_jar_version} -Dfortify.sca.verbose=true -Dfortify.sca.translateLogfile=translate.log -Dfortify.sca.debug=true ${FORTIFY_TRANSLATE_CMD}
        cmd_4 = sourceanalyzer -b calcite-${calcite_jar_version} ${FORTIFY_SCAN_LARGE_MEMORY} -scan -f calcite-${calcite_jar_version}.fpr

    [[xml-replace]]
        REPLACE_1 = 'activeByDefault' , false , pom.xml
        REPLACE_2 = 'avatica.version', ${avatica_jar_version}, pom.xml

[datafu]
build_tool = gradle

    [[artifacts]]
        artifact_1 = datafu-pig/build/libs/datafu-pig-${datafu_jar_version}.jar
        artifact_2 = datafu-pig/build/libs/datafu-pig-${datafu_jar_version}-core.jar
        artifact_3 = datafu-pig/build/libs/datafu-pig-${datafu_jar_version}-javadoc.jar
        artifact_4 = datafu-pig/build/libs/datafu-pig-${datafu_jar_version}-sources.jar

    [[install_cmd]]
        cmd_0 = ${GRADLE_CMD} -b bootstrap.gradle
        cmd_1 = ./gradlew -Pversion=${datafu_jar_version} -Prelease=true :datafu-pig:assemble install

    [[test_cmd]]
        cmd_1 = ${GRADLE_CMD} -b bootstrap.gradle && ./gradlew -Pversion=${datafu_jar_version} -Prelease=true

    [[text-replace]]
        REPLACE_1 = "datafu-pig-incubating","datafu-pig", datafu-pig/build.gradle , regex_replace

[druid]
build_tool = maven
setversion_cmd = ${MVN333_CMD} org.codehaus.mojo:versions-maven-plugin:2.1:set -DgenerateBackupPoms=false -DnewVersion=${druid_jar_version}
deploy_cmd = "${MVN333_CMD} deploy -Drepo.id=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.repo=${NEXUS_REPO_URL} -DskipITs -DskipTests"
COMMON_BUILD_OPTS = "${MVN333_CMD} -DskipTests -Ddruid.distribution.pulldeps.opts='-c io.druid.extensions.contrib:ambari-metrics-emitter' -DrepoOrgUrl=${NEXUS_PROXY_URL}"
coverage_tool = cobertura

    [[artifacts]]
        artifact_1 = distribution/target/druid-${druid_jar_version}-bin.tar.gz
        artifact_2 = distribution/target/mysql-metadata-storage-${druid_jar_version}.tar.gz

    [[install_cmd]]
        cmd_1 =  ${COMMON_BUILD_OPTS} clean install

    [[install_coverage_cmd]]
        cmd_1 =  ${COMMON_BUILD_OPTS} clean

    [[test_cmd]]
        cmd_1 = ${MVN333_CMD} -DfailIfNoTests=false -Djava.net.preferIPv4Stack=true test

    [[test_coverage_cmd]]
        cmd_1 = ${MVN333_CMD} -DfailIfNoTests=false -Djava.net.preferIPv4Stack=true cobertura:cobertura

    [[fortify_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} install
        cmd_2 = ${COMMON_BUILD_OPTS} ${FORTIFY_ARGS} -Dfortify.sca.buildId=druid-${druid_jar_version} ${FORTIFY_CLEAN_CMD}
        cmd_3 = ${COMMON_BUILD_OPTS} ${FORTIFY_ARGS} -Dfortify.sca.buildId=druid-${druid_jar_version} -Dfortify.sca.verbose=true -Dfortify.sca.translateLogfile=translate.log -Dfortify.sca.debug=true ${FORTIFY_TRANSLATE_CMD}
        cmd_4 = sourceanalyzer -b druid-${druid_jar_version} ${FORTIFY_SCAN_LARGE_MEMORY} -scan -f druid-${druid_jar_version}.fpr

    [[xml-replace]]
        REPLACE_1 = 'hadoop.compile.version', ${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml

    [[text-replace]]
        REPLACE_1 = '"https://repo1.maven.org/maven2/"', '"https://repo1.maven.org/maven2/", "${NEXUS_PROXY_URL}"', services/src/main/java/io/druid/cli/PullDependencies.java, regex_replace
        REPLACE_2 = '"org.apache.hadoop:hadoop-client:.*"', '"org.apache.hadoop:hadoop-client:${hadoop_jar_version}"', indexing-service/src/main/java/io/druid/indexing/common/config/TaskConfig.java, regex_replace
        REPLACE_3 = '"org.apache.hadoop:hadoop-client:.*"', '"org.apache.hadoop:hadoop-client:${hadoop_jar_version}"', examples/conf/druid/middleManager/runtime.properties, regex_replace
        REPLACE_4 = '"org.apache.hadoop:hadoop-client:.*"', '"org.apache.hadoop:hadoop-client:${hadoop_jar_version}"', examples/conf-quickstart/druid/middleManager/runtime.properties, regex_replace
        REPLACE_5 = 'conf/druid', 'conf', examples/bin/node.sh, regex_replace
        REPLACE_6 = 'var/druid/pids', '/var/run/druid', examples/bin/node.sh, regex_replace
        REPLACE_7 = 'var/druid/task', '/apps/druid/tasks', examples/conf/druid/middleManager/runtime.properties, regex_replace
        REPLACE_8 = 'var/druid/segment-cache', '/apps/druid/segmentCache', examples/conf/druid/historical/runtime.properties, regex_replace

[gcs]
build_tool = maven
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${gcs_jar_version}
deploy_cmd = ${MVN_CMD} deploy -DskipITs -DskipTests -Psite -Dmaven.javadoc.skip=true
package_count = 3
replace_lkgb_version = ${hdp_latest_version}

    [[install_cmd]]
        cmd_1 = ${MVN_HOME}/bin/mvn -B -U clean -Phadoop3 install -DskipTests

    [[xml-replace]]
        REPLACE_1 = 'hadoop.three.version' , ${hadoop_lkgb_jar_version} , pom.xml
        REPLACE_2 = 'bigdataoss.version' , ${gcs_jar_version} , pom.xml


[hadoop]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN_CMD} -Drequire.snappy=true -Dbundle.snappy=true -Dsnappy.prefix=x -Dsnappy.lib=${snappylib} -Pyarn-ui -Pdist -Pnative -Dtar -Psrc -Pgpg -Drequire.openssl=true -Dmaven.javadoc.skip=true -Dhbase.profile=2.0"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${hadoop_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} -DdistMgmtStagingId=${NEXUS_DEPLOY_REPO_ID} -DdistMgmtStagingUrl=${NEXUS_REPO_URL} -DskipTests -DskipITs deploy
coverage_tool = cobertura

    [[artifacts]]
        artifact_1 = hadoop-dist/target/hadoop-${hadoop_jar_version}.tar.gz
        artifact_2 = hadoop-client-modules/hadoop-client/target/hadoop-client-${hadoop_jar_version}.tar.gz
        artifact_3 = hadoop-hdfs-project/hadoop-hdfs/target/hadoop-hdfs-${hadoop_jar_version}.tar.gz
        artifact_4 = hadoop-hdfs-project/hadoop-hdfs-native-client/target/main/native/fuse-dfs/fuse_dfs

    [[download_modules]]
        cmd_1 = ${S3_DEV_LOC}/tars/isa_l/isal-${isa_l_jar_version}.tar.gz, ${TMP_PACKAGES_DIR}/isal-${isa_l_jar_version}.tar.gz

    [[install_cmd]]
        cmd_1 = tar -zxf ${TMP_PACKAGES_DIR}/isal-${isa_l_jar_version}.tar.gz -C ${TMP_PACKAGES_DIR}
        cmd_2 = ${COMMON_BUILD_OPTS} -DdistMgmtStagingId=${NEXUS_DEPLOY_REPO_ID} -DdistMgmtStagingUrl=${NEXUS_REPO_URL} -Dcontainer-executor.additional_cflags='-std=c90' -DskipTests -DskipITs -Drequire.isal -Disal.lib=${TMP_PACKAGES_DIR}/isal-${isa_l_jar_version}/lib install
        cmd_3 = ${COMMON_BUILD_OPTS} -DdistMgmtStagingId=${NEXUS_DEPLOY_REPO_ID} -DdistMgmtStagingUrl=${NEXUS_REPO_URL} -DskipTests -DskipITs site:site

    [[fortify_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} -DdistMgmtStagingId=${NEXUS_DEPLOY_REPO_ID} -DdistMgmtStagingUrl=${NEXUS_REPO_URL} -Dcontainer-executor.additional_cflags='-std=c90' -DskipTests -DskipITs -Drequire.isal -Disal.lib=${TMP_PACKAGES_DIR}/isal-${isa_l_jar_version}/lib install
        cmd_2 = ${COMMON_BUILD_OPTS} -DdistMgmtStagingId=${NEXUS_DEPLOY_REPO_ID} -DdistMgmtStagingUrl=${NEXUS_REPO_URL} -Dcontainer-executor.additional_cflags='-std=c90' -DskipTests -DskipITs -Drequire.isal -Disal.lib=${TMP_PACKAGES_DIR}/isal-${isa_l_jar_version}/lib ${FORTIFY_ARGS} -Dfortify.sca.buildId=hadoop-${hadoop_jar_version} ${FORTIFY_CLEAN_CMD}
        cmd_3 = ${COMMON_BUILD_OPTS} -DdistMgmtStagingId=${NEXUS_DEPLOY_REPO_ID} -DdistMgmtStagingUrl=${NEXUS_REPO_URL} -Dcontainer-executor.additional_cflags='-std=c90' -DskipTests -DskipITs -Drequire.isal -Disal.lib=${TMP_PACKAGES_DIR}/isal-${isa_l_jar_version}/lib ${FORTIFY_ARGS} -Dfortify.sca.buildId=hadoop-${hadoop_jar_version} -Dfortify.sca.verbose=true -Dfortify.sca.translateLogfile=translate.log -Dfortify.sca.debug=true ${FORTIFY_TRANSLATE_CMD}
    	cmd_4 = sourceanalyzer -b hadoop-${hadoop_jar_version} ${FORTIFY_SCAN_LARGE_MEMORY} -scan -f hadoop-${hadoop_jar_version}.fpr

    [[test_cmd]]
        cmd_1 = ${MVN_CMD} test

    [[test_coverage_cmd]]
        cmd_1 = ${MVN_CMD} cobertura:cobertura

    [[xml-replace]]
        REPLACE_1 = 'forkedProcessTimeoutInSeconds', '1800' , hadoop-project/pom.xml
        REPLACE_2 = 'forkedProcessTimeoutInSeconds', '1800' , hadoop-tools/hadoop-distcp/pom.xml
        REPLACE_3 = 'argLine', '-Xms2048m -Xmx3072m -XX:MaxPermSize=2048m -XX:+HeapDumpOnOutOfMemoryError', hadoop-project/pom.xml
        REPLACE_4 = 'argLine', '-Xms2048m -Xmx3072m -XX:MaxPermSize=2048m -XX:+HeapDumpOnOutOfMemoryError', hadoop-tools/hadoop-distcp/pom.xml
        REPLACE_5 = 'zookeeper.version', ${zookeeper_jar_version} , pom.xml
        REPLACE_7 = 'gcs.version' , ${gcs_jar_version} , hadoop-project/pom.xml


[hadooplzo]
build_tool = maven
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${hadooplzo_jar_version}

    [[artifacts]]
        artifact_1 = target/hadooplzo-${hadooplzo_jar_version}.tar.gz

    [[install_cmd]]
        cmd_1 = "${MVN_CMD} -Dversion=${hadooplzo_jar_version} -Dhadoop.version=${hadoop_jar_version} -Drepo.maven.org=${NEXUS_REPO_URL} -Dmvnrepo=${NEXUS_REPO_URL} clean install package -Dmaven.javadoc.skip=true"
        cmd_2 = "tar -zvcf hadooplzo-${hadooplzo_jar_version}.tar.gz native hadoop-lzo-${hadooplzo_jar_version}.jar  hadoop-lzo-${hadooplzo_jar_version}-sources.jar --exclude=native/Linux-amd64-64/src --exclude=native/Linux-amd64-64/.libs --exclude=native/Linux-amd64-64/impl --exclude=native/Linux-amd64-64/libgplcompression.la --exclude=native/Linux-amd64-64/Makefile --exclude=native/Linux-amd64-64/config.status --exclude=native/Linux-amd64-64/config.log --exclude=native/Linux-amd64-64/libtool" , target

    [[xml-replace]]
        REPLACE_1 = 'hadoop.current.version', ${hadoop_jar_version} , pom.xml

[hbase]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN_CMD} -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Drepourl=${NEXUS_REPO_URL} clean"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${hbase_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} deploy -DskipTests=true -Dmaven.javadoc.skip=true
coverage_tool = cobertura

    [[artifacts]]
        artifact_1 = hbase-assembly/target/hbase-${hbase_jar_version}-bin.tar.gz
        artifact_2 = hbase-thrift/src/main/resources/org/apache/hadoop/hbase/thrift/Hbase.thrift
        artifact_3 = hbase-thrift/src/main/resources/org/apache/hadoop/hbase/thrift2/hbase.thrift

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} install assembly:single -DskipTests=true -Dhadoop.profile=3.0

    [[fortify_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} install assembly:single -DskipTests=true -Dhadoop.profile=3.0
        cmd_2 = ${COMMON_BUILD_OPTS} -DskipTests=true -Dhadoop.profile=3.0 ${FORTIFY_ARGS} -Dfortify.sca.buildId=hbase-${hbase_jar_version} ${FORTIFY_CLEAN_CMD}
        cmd_3 = ${COMMON_BUILD_OPTS} -DskipTests=true -Dhadoop.profile=3.0 ${FORTIFY_ARGS} -Dfortify.sca.buildId=hbase-${hbase_jar_version} ${FORTIFY_TRANSLATE_CMD}
        cmd_4 = sourceanalyzer -b hbase-${hbase_jar_version} ${FORTIFY_SCAN_MEMORY} -scan -f hbase-${hbase_jar_version}.fpr

    # "package" is the recommended lifecycle phase for running unit tests for Maven projects.
    # Also, MAWO may choose to run UTs that span Maven modules. Without the fail-never option, the failure
    # of a UT in an earlier module may preclude execution of the tests in a later module.
   [[test_cmd]]
        cmd_1 = ${MVN_CMD} --fail-never -Phadoop-3.0 package

   [[test_coverage_cmd]]
        cmd_1 = ${MVN_CMD} --fail-never -Phadoop-3.0 cobertura:cobertura

    [[xml-replace]]
        REPLACE_1 = 'hadoop-one.version',${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'hadoop-two.version', ${hadoop_jar_version}, pom.xml
        REPLACE_3 = 'hadoop-three.version', ${hadoop_jar_version}, pom.xml
        REPLACE_4 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml
        REPLACE_5 = 'surefire.firstPartThreadCount', '1', pom.xml
        REPLACE_6 = 'surefire.secondPartThreadCount', '1', pom.xml
        REPLACE_7 = 'surefire.timeout', '7200', pom.xml
        REPLACE_8 = 'activeByDefault' , 'false' , pom.xml
        REPLACE_9 = 'hbase.version' , ${hbase_jar_version} , pom.xml
        REPLACE_10 = 'spark.version' , ${spark2_lkgb_jar_version} , pom.xml

[storage_api]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN_CMD}"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${storage_api_jar_version} , storage-api
deploy_cmd = "${COMMON_BUILD_OPTS} clean deploy -DskipTests" , storage-api

    [[install_cmd]]
        cmd_1 = "${COMMON_BUILD_OPTS} clean  install -DskipTests -Dmaven.javadoc.skip=true -Denforcer.skip=true" , storage-api

    [[test_cmd]]
        cmd_1 = "${COMMON_BUILD_OPTS} test-compile -Dmaven.test.failure.ignore=true" , storage-api

    [[xml-replace]]
        REPLACE_1 = 'hadoop.version', ${hadoop_jar_version}, pom.xml

[oozie]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN311_CMD} -fae -Dhadoop.version=${hadoop_jar_version} -Dhive.version=${hive_jar_version} -Dpig.version=${pig_jar_version} -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Dreponame=${NEXUS_DEPLOY_REPO_ID} -Drepourl=${NEXUS_REPO_URL} -DdistMgmtReleaseUrl=${NEXUS_REPO_URL} -DmavenReleaseId=${NEXUS_DEPLOY_REPO_ID} -Pgpg,hadoop-2,!hadoop-1,uber,hwx-common"
setversion_cmd = ${MVN311_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${oozie_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} deploy -DskipITs -DskipTests=true
coverage_tool = cobertura

    [[artifacts]]
        artifact_1 = distro/target/oozie-${oozie_jar_version}-distro.tar.gz
        artifact_2 = HDP-CHANGES.txt
        artifact_3 = LICENSE.txt
        artifact_4 = NOTICE.txt
        artifact_5 = README.txt
        artifact_6 = release-log.txt
        artifact_7 = source-headers.txt

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} install -DskipITs -DskipTests=true
        cmd_2 = ${COMMON_BUILD_OPTS} -DskipITs -DskipTests=true package assembly:single

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} ${MAVEN_TEST_OPTS} -Djava.net.preferIPv4Stack=true test

    [[test_coverage_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} ${MAVEN_TEST_OPTS} -Djava.net.preferIPv4Stack=true cobertura:cobertura

    [[fortify_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} -DskipITs -DskipTests clean install
        cmd_2 = ${COMMON_BUILD_OPTS} -DskipITs -DskipTests ${FORTIFY_ARGS} -Dfortify.sca.buildId=oozie-${oozie_jar_version} ${FORTIFY_CLEAN_CMD}
        cmd_3 = ${COMMON_BUILD_OPTS} -DskipITs -DskipTests ${FORTIFY_ARGS} -Dfortify.sca.buildId=oozie-${oozie_jar_version} ${FORTIFY_TRANSLATE_CMD}
    	cmd_4 = sourceanalyzer -b oozie-${oozie_jar_version} ${FORTIFY_SCAN_MEMORY} -scan -f oozie-${oozie_jar_version}.fpr

    [[text-replace]]
        REPLACE_1 = '<version>hadoop-2-.*</version>', '<version>hadoop-2-${oozie_jar_version}</version>', hadooplibs/hadoop-auth-2/pom.xml, regex_replace
        REPLACE_2 = '<version>hadoop-2-.*</version>', '<version>hadoop-2-${oozie_jar_version}</version>', hadooplibs/hadoop-distcp-2/pom.xml, regex_replace
        REPLACE_3 = '<version>hadoop-2-.*</version>', '<version>hadoop-2-${oozie_jar_version}</version>', hadooplibs/hadoop-utils-2/pom.xml, regex_replace

    [[xml-replace]]
        REPLACE_1 = 'hbase.version' , ${hbase_jar_version} , pom.xml
        REPLACE_2 = 'hbaselib.version' , ${hbase_jar_version}.oozie-${oozie_jar_version} , pom.xml
        REPLACE_3 = 'hcatalog.version' , ${hive_jar_version} , pom.xml
        REPLACE_4 = 'sqoop.version' , ${sqoop_jar_version} , pom.xml
        REPLACE_5 = 'pig.version' , ${pig_jar_version} , pom.xml
        REPLACE_6 = 'hive.version' , ${hive_jar_version} , pom.xml
        REPLACE_7 = 'tez.version' , ${tez_jar_version} , pom.xml
        REPLACE_8 = 'hadoop.auth.version' , ${hadoop_jar_version} , pom.xml
        REPLACE_9 = 'hadoopTwo.version' , ${hadoop_jar_version} , pom.xml
        REPLACE_11 = 'activeByDefault' , 'false' , pom.xml
        REPLACE_12 = 'hadoop.version' , ${hadoop_jar_version} , pom.xml
        REPLACE_13 = 'spark.version' , ${spark2_jar_version} , pom.xml
        REPLACE_14 = 'gcs.version' , ${gcs_jar_version} , pom.xml


[orc]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN_CMD}"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${orc_jar_version} , java
deploy_cmd = "${COMMON_BUILD_OPTS} clean deploy -DskipTests" , java

    [[install_cmd]]
        cmd_1 = "${COMMON_BUILD_OPTS} clean  install -DskipTests -Dmaven.javadoc.skip=true -Denforcer.skip=true" , java

    [[test_cmd]]
        cmd_1 = "${COMMON_BUILD_OPTS} test-compile -Dmaven.test.failure.ignore=true" , java

    [[xml-replace]]
        REPLACE_1 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'storage-api.version', ${storage_api_jar_version}, pom.xml
        REPLACE_3 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml

[hive]
build_tool = maven
hive_alternate_name = apache-hive
hive_apache_base_maven_version = 1.2.1
COMMON_BUILD_OPTS = "${MVN_CMD} -Dhadoop.mr.rev=23 -DskipSparkTests -Drepo.maven.org=${NEXUS_PROXY_URL} -Dtest.junit.output.format=xml -Dmvn.hadoop.profile=hadoop23 -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Drepourl=${NEXUS_REPO_URL} -Dmvnrepo=${NEXUS_PROXY_URL}"
deploy_cmd = "${COMMON_BUILD_OPTS} clean deploy -DskipTests -Phadoop-2,dist,sources"
coverage_tool = cobertura

    [[artifacts]]
        artifact_1 = packaging/target/${hive_alternate_name}-${hive_jar_version}-bin.tar.gz

    [[setversion_cmd]]
        cmd_1 = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${hive_jar_version}
        cmd_2 = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${hive_jar_version} , storage-api
        cmd_3 = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${hive_jar_version}, standalone-metastore
        cmd_4 = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${hive_jar_version}, upgrade-acid

    [[install_cmd]]
        cmd_1 = "${COMMON_BUILD_OPTS} clean  install -DskipTests -Pdist,sources -Dmaven.javadoc.skip=true -Denforcer.skip=true"

    [[fortify_cmd]]
        cmd_1 = "${COMMON_BUILD_OPTS} clean  install -DskipTests -Pdist,sources -Dmaven.javadoc.skip=true -Denforcer.skip=true"
        cmd_2 = "${COMMON_BUILD_OPTS} -DskipTests -Pdist,sources -Dmaven.javadoc.skip=true -Denforcer.skip=true ${FORTIFY_ARGS} -Dfortify.sca.buildId=hive2-${hive_jar_version} ${FORTIFY_CLEAN_CMD}"
        cmd_3 = "${COMMON_BUILD_OPTS} -DskipTests -Pdist,sources -Dmaven.javadoc.skip=true -Denforcer.skip=true ${FORTIFY_ARGS} -Dfortify.sca.buildId=hive2-${hive_jar_version} -Dfortify.sca.verbose=true -Dfortify.sca.translateLogfile=translate.log -Dfortify.sca.debug=true ${FORTIFY_TRANSLATE_CMD}"
    	cmd_4 = sourceanalyzer -b hive2-${hive_jar_version} ${FORTIFY_SCAN_LARGE_MEMORY} -scan -f hive2-${hive_jar_version}.fpr

    [[test_cmd]]
        cmd_1 = "${COMMON_BUILD_OPTS} test-compile -Dmaven.test.failure.ignore=true"

    [[test_coverage_cmd]]
        cmd_1 = "${COMMON_BUILD_OPTS} cobertura:cobertura -Dmaven.test.failure.ignore=true"

    [[text-replace]]
        REPLACE_1 = "${hive_apache_base_maven_version}-SNAPSHOT", ${hive_jar_version}, pom.xml , key_value
        REPLACE_2 = "${hive_apache_base_maven_version}", ${hive_jar_version}, pom.xml , key_value

    [[xml-replace]]
        REPLACE_1 = 'accumulo.version', ${accumulo_jar_version}, pom.xml
        REPLACE_2 = 'calcite.version', ${calcite_jar_version}, pom.xml
        REPLACE_3 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_4 = 'hbase.version', ${hbase_jar_version}, pom.xml
        REPLACE_5 = 'hbase.hadoop2.version', ${hbase_jar_version}, pom.xml
        REPLACE_6 = 'tez.version', ${tez_jar_version}, pom.xml
        REPLACE_8 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml
        REPLACE_10 = 'storage-api.version', ${storage_api_jar_version}, pom.xml
        REPLACE_11 = 'orc.version', ${orc_jar_version}, pom.xml
        REPLACE_12 = 'druid.version', ${druid_jar_version}, pom.xml
        REPLACE_13 = 'arrow.version', ${arrow_jar_version}, pom.xml
        REPLACE_14 = 'parquet.version', ${parquet_jar_version}, pom.xml

[isa_l]

    [[artifacts]]
        artifact_1 = isal-${isa_l_jar_version}.tar.gz

    [[install_cmd]]
        cmd_1 = sh autogen.sh
        cmd_2 = ./configure --prefix=${SOURCE_ROOT}/isa_l/isal-${isa_l_jar_version}
        cmd_3 = make
        cmd_4 = make install
        cmd_5 = tar -zcf isal-${isa_l_jar_version}.tar.gz isal-${isa_l_jar_version}

[kafka]
build_tool = gradle
COMMON_BUILD_OPTS = "{GRADLE_CMD} ${GRADLE_OPTS} "
deploy_cmd = ${COMMON_BUILD_OPTS} deploy
kafka_scala_version = 2.11
kafka_scala_version_compile = 2.11.12
package_count = 2

BUILD_KAFKA_SETVERSION_OPTS = "-Pversion=${kafka_jar_version}"
BUILD_KAFKA_OPTS = "${BUILD_KAFKA_SETVERSION_OPTS}"
BUILD_KAFKA_DOC_OPTS = "${BUILD_KAFKA_OPTS} docsJar"
BUILD_KAFKA_INSTALL_OPTS = "${BUILD_KAFKA_OPTS} clean jar"
BUILD_KAFKA_EXAMPLES_INSTALL_OPTS = "${BUILD_KAFKA_OPTS} examples:jar"
BUILD_KAFKA_CONTRIB_CONSUMER_INSTALL_OPTS = "${BUILD_KAFKA_OPTS} contrib:hadoop-consumer:jar"
BUILD_KAFKA_CONTRIB_PRODUCER_INSTALL_OPTS = "${BUILD_KAFKA_OPTS} contrib:hadoop-producer:jar"
BUILD_KAFKA_CONTRIB_GANGLIA_INSTALL_OPTS = "${BUILD_KAFKA_OPTS} contrib:kafka-ganglia:jar"
BUILD_KAFKA_PERF_INSTALL_OPTS = "${BUILD_KAFKA_OPTS} perf:jar"
BUILD_KAFKA_DEPLOY_OPTS = "${BUILD_KAFKA_OPTS} releaseTarGz"
BUILD_KAFKA_TEST_OPTS = "${BUILD_KAFKA_OPTS} cleanTest test -PrepoUrl=http://${NEXUS_HOST}/nexus/content/groups/public"
BUILD_KAFKA_UPLOAD = "${BUILD_KAFKA_SETVERSION_OPTS} installAll"

    [[artifacts]]
        artifact_1 = core/build/distributions/kafka_${kafka_scala_version}-${kafka_jar_version}.tgz
        artifact_2 = kafka.tar.gz

    [[install_cmd]]
        cmd_0 = gradle
        cmd_1 = ./gradlew ${BUILD_KAFKA_SETVERSION_OPTS}
        cmd_2 = ./gradlew ${BUILD_KAFKA_INSTALL_OPTS}
        cmd_3 = ./gradlew ${BUILD_KAFKA_DOC_OPTS}
        cmd_4 = ./gradlew ${BUILD_KAFKA_EXAMPLES_INSTALL_OPTS}
        cmd_5 = ./gradlew ${BUILD_KAFKA_CONTRIB_GANGLIA_INSTALL_OPTS}
        cmd_6 = ./gradlew ${BUILD_KAFKA_DEPLOY_OPTS}
        cmd_7 = ./gradlew ${BUILD_KAFKA_UPLOAD}
        cmd_8= "mv contrib/kafka-ganglia/build/libs/kafka-ganglia-${kafka_jar_version}.jar contrib/kafka-ganglia/build/libs/lib/"
        cmd_9 = "mv contrib/kafka-ganglia/build/libs/kafka-ganglia-${kafka_jar_version}-javadoc.jar contrib/kafka-ganglia/build/libs/lib/"
        cmd_10 =  "tar -zcvf kafka.tar.gz core/build/docs contrib/kafka-ganglia/build/libs/lib/ contrib/build/libs/  examples/build/libs NOTICE LICENSE"

   [[test_cmd]]
        cmd_1 = ./gradlew ${BUILD_KAFKA_TEST_OPTS}

   [[fortify_cmd]]
        # TO DO Replace gradlew PATH. For now hard coding the path.
        cmd_0 = sourceanalyzer -b kafka-${kafka_jar_version} -source "1.7" gradle
        cmd_1 = sourceanalyzer -b kafka-${kafka_jar_version} -source "1.7" /grid/0/jenkins/workspace/Fortify-SCA-3/SOURCES/kafka/gradlew ${BUILD_KAFKA_SETVERSION_OPTS}
        cmd_2 = sourceanalyzer -b kafka-${kafka_jar_version} -source "1.7" /grid/0/jenkins/workspace/Fortify-SCA-3/SOURCES/kafka/gradlew ${BUILD_KAFKA_INSTALL_OPTS}
        cmd_3 = sourceanalyzer -b kafka-${kafka_jar_version} -source "1.7" /grid/0/jenkins/workspace/Fortify-SCA-3/SOURCES/kafka/gradlew ${BUILD_KAFKA_DOC_OPTS}
        cmd_4 = sourceanalyzer -b kafka-${kafka_jar_version} -source "1.7" /grid/0/jenkins/workspace/Fortify-SCA-3/SOURCES/kafka/gradlew ${BUILD_KAFKA_EXAMPLES_INSTALL_OPTS}
        cmd_5 = sourceanalyzer -b kafka-${kafka_jar_version} -source "1.7" /grid/0/jenkins/workspace/Fortify-SCA-3/SOURCES/kafka/gradlew ${BUILD_KAFKA_CONTRIB_GANGLIA_INSTALL_OPTS}
        cmd_6 = sourceanalyzer -b kafka-${kafka_jar_version} ${FORTIFY_SCAN_MEMORY} -scan -f kafka-${kafka_jar_version}.fpr

   [[text-replace]]
        REPLACE_1 = 'scalaVersion', ${kafka_scala_version_compile}, gradle.properties , key_value
        REPLACE_2 = 'version', ${kafka_jar_version}, gradle.properties , key_value
        REPLACE_3 = 'zookeeperVersion', ${zookeeper_jar_version}, gradle.properties , key_value
        REPLACE_4 = 'pigVersion', ${pig_jar_version}, gradle.properties , key_value
        REPLACE_5 = 'hadoopVersion', ${hadoop_jar_version}, gradle.properties , key_value
        REPLACE_6 = 'repoUrl', ${NEXUS_PROXY_URL}, gradle.properties , key_value
        REPLACE_7 = 'mavenUrl', ${NEXUS_REPO_URL}, gradle.properties , key_value

[phoenix]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN_CMD} -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Dreponame=${NEXUS_DEPLOY_REPO_ID} -Drepourl=${NEXUS_REPO_URL} -Drepo.maven.org=${NEXUS_PROXY_URL}"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${phoenix_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} clean package deploy -Pgpg -DskipITs -DskipTests

    [[artifacts]]
        artifact_1 = phoenix-assembly/target/phoenix-${phoenix_jar_version}.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} clean install -DskipITs -DskipTests -Dmaven.javadoc.skip=true

    [[fortify_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} -DskipITs -DskipTests -Dmaven.javadoc.skip=true clean install
        cmd_2 = ${COMMON_BUILD_OPTS} -DskipITs -DskipTests -Dmaven.javadoc.skip=true ${FORTIFY_ARGS} -Dfortify.sca.buildId=phoenix-${phoenix_jar_version} ${FORTIFY_CLEAN_CMD}
        cmd_3 = ${COMMON_BUILD_OPTS} -DskipITs -DskipTests -Dmaven.javadoc.skip=true ${FORTIFY_ARGS} -Dfortify.sca.buildId=phoenix-${phoenix_jar_version} ${FORTIFY_TRANSLATE_CMD}
    	cmd_4 = sourceanalyzer -b phoenix-${phoenix_jar_version} ${FORTIFY_SCAN_MEMORY} -scan -f phoenix-${phoenix_jar_version}.fpr

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} ${MAVEN_TEST_OPTS} -DfailIfNoTests=false -DreuseForks=false verify

    [[test_coverage_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} ${MAVEN_TEST_OPTS} -DfailIfNoTests=false -DreuseForks=false cobertura:cobertura

    [[xml-replace]]
        REPLACE_2 = 'hadoop-two.version', ${hadoop_jar_version}, pom.xml
        REPLACE_3 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_4 = 'hbase.version', ${hbase_jar_version}, pom.xml
        REPLACE_5 = 'pig.version', ${pig_jar_version}, pom.xml
        REPLACE_7 = 'avatica.version', ${avatica_jar_version}, pom.xml
        REPLACE_8 = 'calcite.version', ${calcite_jar_version}, pom.xml
        REPLACE_9 = 'hive.version', ${hive_jar_version}, pom.xml
        REPLACE_10 = 'spark.version', ${spark2_jar_version}, pom.xml

[pig]
build_tool = ant
COMMON_BUILD_OPTS = "${ANT_CMD} -Djavac.version=1.7 -Dversion=${pig_jar_version} -Dzookeeper.version=${zookeeper_jar_version} -Dhive.version=${hive_jar_version} -Dtez.version=${tez_jar_version} -Daccumulo15.version=${accumulo_jar_version} -Dhbase2.version=${hbase_jar_version} -Dhadoop-common.version=${hadoop_jar_version} -Dhadoop-hdfs.version=${hadoop_jar_version} -Dhadoop-mapreduce.version=${hadoop_jar_version} -Dtest.junit.output.format=xml -Dforrest.home=${FORREST_HOME} -Dhadoopversion=23 -Dorc.version=${orc_jar_version} -Dmvnrepo=${NEXUS_PROXY_URL} -Drepo.apache.snapshots=${NEXUS_PROXY_URL} -Drepo.jboss.org=${NEXUS_PROXY_URL}"
deploy_cmd = ${COMMON_BUILD_OPTS} -f nexus-build.xml -Dstaging_repo_id=${NEXUS_DEPLOY_REPO_ID} -Dasfstagingrepo=${NEXUS_REPO_URL} stage
BUILD_PIG_COMPILE_JAR="${COMMON_BUILD_OPTS} very-clean jar pigunit-jar smoketests-jar compile-test"

    [[artifacts]]
        artifact_1 = build/pig-${pig_jar_version}.tar.gz
        artifact_2 = pig.tar.gz
        artifact_3 = build/pig-${pig_jar_version}-smoketests.jar

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} mvn-install
        cmd_2 = ${COMMON_BUILD_OPTS} very-clean jar pigunit-jar smoketests-jar compile-test
        cmd_3 = ${COMMON_BUILD_OPTS} -buildfile contrib/piggybank/java/build.xml clean jar
        cmd_4 = ${COMMON_BUILD_OPTS} -Dant-task.version=2.1.3 tar
        cmd_5 = "tar -cz --exclude-vcs --transform 's,^build\/tar\/pig-${pig_jar_version}\/,pig/,' -f pig.tar.gz build/tar/pig-${pig_jar_version}"

    [[fortify_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} mvn-install
        cmd_2 = ${COMMON_BUILD_OPTS} very-clean jar pigunit-jar smoketests-jar compile-test
        cmd_3 = ${COMMON_BUILD_OPTS} -buildfile contrib/piggybank/java/build.xml clean jar
        cmd_4 = ${COMMON_BUILD_OPTS} -Dant-task.version=2.1.3 tar
        cmd_5 = "tar -cz --exclude-vcs --transform 's,^build\/tar\/pig-${pig_jar_version}\/,pig/,' -f pig.tar.gz build/tar/pig-${pig_jar_version}"
        cmd_6 = ${COMMON_BUILD_OPTS} -Dbuild.compiler=com.fortify.dev.ant.SCACompiler -Dsourceanalyzer.buildid=${pig_jar_version} -lib ${FORTIFY_SCA_HOME}/Core/lib/sourceanalyzer.jar -Dsourceanalyzer.maxHeap=32G
        # cmd_7 = sourceanalyzer -b ${pig_jar_version} -Xmx48G -verbose -cp "./jars/*.jar" -source "1.7" "**/*.jsp" "**/*.xml" "**/*.js" "**/*.properties" "**/*.java"
        cmd_7 = sourceanalyzer -b ${pig_jar_version} -Xmx48G -verbose -cp "./jars/*.jar" -source "1.7" "src/**/*.java"
        cmd_8 = sourceanalyzer -b ${pig_jar_version} -Xmx48G -scan -f ${pig_jar_version}.fpr

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} -Dant-task.version=2.1.3 test-core-mrtez


[pydruid]
build_tool = python
no_package = True

        [[artifacts]]
           artifact_1 = dist/pydruid-0.4.2-py2.py3-none-any.whl

    [[install_cmd]]
           cmd_1 = ${BASE_DIR}/buildvenv/bin/python setup.py bdist_wheel

[parquet]
build_tool = maven
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${parquet_jar_version}
deploy_cmd = "${MVN_CMD} deploy -Drepo.id=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.repo=${NEXUS_REPO_URL} -DskipITs -DskipTests"
PATH=${PROTOBUF351_HOME}/bin:${PATH}
no_package = True

    [[install_cmd]]
        cmd_1 = ${MVN_CMD} -B clean install -DskipTests

    [[xml-replace]]
        REPLACE_1 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'pig.version', ${pig_lkgb_jar_version}, pom.xml

[ranger]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN333_CMD} -DskipCheck=true -Dcheckstyle.skip=true -DdistMgmtStagingId=${NEXUS_DEPLOY_REPO_ID} -DdistMgmtStagingUrl=${NEXUS_REPO_URL}"
setversion_cmd = ${MVN333_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${ranger_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} package assembly:assembly deploy -Pgpg -DskipITs -DskipTests -Dmaven.javadoc.skip=true

    [[artifacts]]
        artifact_1 = target/ranger-${ranger_jar_version}-admin.tar.gz
        artifact_2 = target/ranger-${ranger_jar_version}-hbase-plugin.tar.gz
        artifact_3 = target/ranger-${ranger_jar_version}-hdfs-plugin.tar.gz
        artifact_4 = target/ranger-${ranger_jar_version}-hive-plugin.tar.gz
        artifact_5 = target/ranger-${ranger_jar_version}-kafka-plugin.tar.gz
        artifact_6 = target/ranger-${ranger_jar_version}-kms.tar.gz
        artifact_7 = target/ranger-${ranger_jar_version}-knox-plugin.tar.gz
        artifact_8 = target/ranger-${ranger_jar_version}-migration-util.tar.gz
        artifact_9 = target/ranger-${ranger_jar_version}-ranger-tools.tar.gz
        artifact_10 = target/ranger-${ranger_jar_version}-solr-plugin.tar.gz
        artifact_11 = target/ranger-${ranger_jar_version}-storm-plugin.tar.gz
        artifact_12 = target/ranger-${ranger_jar_version}-tagsync.tar.gz
        artifact_13 = target/ranger-${ranger_jar_version}-usersync.tar.gz
        artifact_14 = target/ranger-${ranger_jar_version}-yarn-plugin.tar.gz
        artifact_15 = target/ranger-${ranger_jar_version}-src.tar.gz
        artifact_16 = target/ranger-${ranger_jar_version}-atlas-plugin.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} package assembly:assembly install -Pgpg -DskipITs -DskipTests -Dmaven.javadoc.skip=true

    [[fortify_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} package assembly:assembly install -Pgpg -DskipITs -DskipTests -Dmaven.javadoc.skip=true
        cmd_2 = ${COMMON_BUILD_OPTS} -Pgpg -DskipTests -DskipITs -Dmaven.javadoc.skip=true ${FORTIFY_ARGS} -Dfortify.sca.buildId=ranger-${ranger_jar_version} ${FORTIFY_CLEAN_CMD}
        cmd_3 = ${COMMON_BUILD_OPTS} -Pgpg -DskipTests -DskipITs -Dmaven.javadoc.skip=true ${FORTIFY_ARGS} -Dfortify.sca.buildId=ranger-${ranger_jar_version} ${FORTIFY_TRANSLATE_CMD}
        cmd_4 = sourceanalyzer -b ranger-${ranger_jar_version} ${FORTIFY_SCAN_MEMORY} -scan -f ranger-${ranger_jar_version}.fpr

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} test -DfailIfNoTests=false ${MAVEN_TEST_OPTS}

    [[test_coverage_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} cobertura:cobertura -DfailIfNoTests=false ${MAVEN_TEST_OPTS}

    [[xml-replace]]
        REPLACE_1 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'hadoop-auth.version', ${hadoop_jar_version}, pom.xml
        REPLACE_3 = 'hadoop-common.version', ${hadoop_jar_version}, pom.xml
        REPLACE_4 = 'hbase.version', ${hbase_jar_version}, pom.xml
        REPLACE_5 = 'hive.version', ${hive_jar_version}, pom.xml
        REPLACE_6 = 'kafka.version', ${kafka_jar_version}, pom.xml
        REPLACE_7 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml
        REPLACE_8 = 'tez.version', ${tez_jar_version}, pom.xml
        REPLACE_9 = 'calcite.version', ${calcite_jar_version}, pom.xml
        REPLACE_10 = 'knox.gateway.version', ${knox_jar_version}, pom.xml
        REPLACE_12 = 'atlas.version', ${atlas_jar_version}, pom.xml


[livy]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN_CMD} ${MAVEN_TEST_OPTS} -Dtar -Pgpg -Dhadoop.version=${hadoop_jar_version} -Drepo.id=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.repository=${NEXUS_REPO_URL} -DaltDeploymentRepository=${NEXUS_DEPLOY_REPO_ID}::default::${NEXUS_REPO_URL} -DdistMgmtStagingId=${NEXUS_DEPLOY_REPO_ID} -DdistMgmtStagingUrl=${NEXUS_REPO_URL}"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${livy_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} deploy
coverage_tool = cobertura

    [[artifacts]]
        artifact_1 = assembly/target/livy-server-${livy_jar_version}.zip

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} install -Dmaven.javadoc.skip=true -DskipTests -Dskip -DskipITs

    [[fortify_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} -Dmaven.javadoc.skip=true -DskipTests -Dskip -DskipITs install
        cmd_2 = ${COMMON_BUILD_OPTS} -Dmaven.javadoc.skip=true -DskipTests -Dskip -DskipITs ${FORTIFY_ARGS} -Dfortify.sca.buildId=livy-${livy_jar_version} ${FORTIFY_CLEAN_CMD}
        cmd_3 = ${COMMON_BUILD_OPTS} -Dmaven.javadoc.skip=true -DskipTests -Dskip -DskipITs ${FORTIFY_ARGS} -Dfortify.sca.buildId=livy-${livy_jar_version} ${FORTIFY_TRANSLATE_CMD}
    	cmd_4 = sourceanalyzer -b livy-${livy_jar_version} ${FORTIFY_SCAN_MEMORY} -scan -f livy-${livy_jar_version}.fpr

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} verify -pl !coverage -pl !python-api

    [[test_coverage_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} cobertura:cobertura -pl !python-api

    [[xml-replace]]
        REPLACE_1 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'spark.version', ${spark2_jar_version}, pom.xml
        REPLACE_3 = 'spark1.version', ${spark_lkgb_jar_version}, pom.xml
        REPLACE_4 = 'spark.version', ${spark_lkgb_jar_version}, repl/scala-2.10/pom.xml
        REPLACE_5 = 'spark.version', ${spark_lkgb_jar_version}, scala-api/scala-2.10/pom.xml

[spark2]
build_tool = maven
BUILD_SPARK_SETVERSION_OPTS = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${spark2_jar_version} -DgenerateBackupPoms=false
COMMON_BUILD_OPTS = "-Phive -Phive-thriftserver -Pyarn -Phadoop-3.1 -Phadoop-cloud -Phwx-common -Pkafka-0-8 -Pflume -Drepo.id=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.repo=${NEXUS_REPO_URL} -Pbigtop-dist -Dsurefire.timeout=9600 ${MAVEN_TEST_OPTS} -Psparkr -Dskip"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${spark2_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} package deploy -DskipTests -Dskip
package_count = 5
coverage_tool = cobertura

   [[PASSTHROUGH_ENV]]
        HADOOP_VERSION=${hadoop_jar_version}
        SPARK2_VERSION=${spark2_jar_version}
    [[artifacts]]
        artifact_1 = spark-${spark2_jar_version}-bin-${hadoop_jar_version}.tgz

    [[install_cmd]]
        cmd_1 = dev/make-distribution.sh --tgz ${COMMON_BUILD_OPTS} -Dskip=true

    [[fortify_cmd]]
        cmd_1 = dev/make-distribution.sh --tgz ${COMMON_BUILD_OPTS} -Dskip=true
        cmd_2 = build/mvn ${COMMON_BUILD_OPTS} -DskipTests -Dmaven.javadoc.skip=true ${FORTIFY_ARGS} -Dfortify.sca.buildId=spark2-${spark2_jar_version} ${FORTIFY_CLEAN_CMD}
        cmd_3 = build/mvn ${COMMON_BUILD_OPTS} -DskipTests -Dmaven.javadoc.skip=true ${FORTIFY_ARGS} -Dfortify.sca.buildId=spark2-${spark2_jar_version} ${FORTIFY_TRANSLATE_CMD}
        cmd_4 = sourceanalyzer -b spark2-${spark2_jar_version} ${FORTIFY_SCAN_MEMORY} -scan -f spark2-${spark2_jar_version}.fpr

    [[test_cmd]]
        cmd_1 = ${MVN_CMD} ${COMMON_BUILD_OPTS} -fae test

    [[test_coverage_cmd]]
        cmd_1 = ${MVN_CMD} ${COMMON_BUILD_OPTS} -fae cobertura:cobertura

    [[xml-replace]]
        REPLACE_2 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_3 = 'hbase.version', ${hbase_jar_version}, pom.xml
        REPLACE_4 = 'protobuf.version', ${protobuf_version}, pom.xml
        REPLACE_5 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml
        REPLACE_6 = 'kafka.version', ${kafka_jar_version}, pom.xml
        REPLACE_7 = 'hive.version', ${spark_hive2_jar_version}, pom.xml
        REPLACE_8 = 'arrow.version', ${arrow_jar_version}, pom.xml


[spark_hive2]
build_tool = maven
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${spark_hive2_jar_version}

    [[install_cmd]]
        cmd_1 = "${MVN_CMD} clean install -Dhadoop.mr.rev=23 -DskipSparkTests -Drepo.maven.org=${NEXUS_PROXY_URL} -Dtest.junit.output.format=xml -Dmvn.hadoop.profile=hadoop23 -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Drepourl=${NEXUS_REPO_URL} -Dmvnrepo=${NEXUS_PROXY_URL} -DskipTests -Phadoop-2,dist,sources -Dmaven.javadoc.skip=true -Dgpg.skip"

    [[xml-replace]]
        #REPLACE_1 = 'hadoop-23.version', ${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'hbase.version', ${hbase_jar_version}, pom.xml
        REPLACE_3 = 'protobuf.version', ${protobuf_version}, pom.xml
        REPLACE_4 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml
        #REPLACE_5 = 'kafka.version', ${kafka_jar_version}, pom.xml
        REPLACE_6 = 'accumulo.version', ${accumulo_jar_version}, pom.xml
        REPLACE_7 = 'hive3.version', ${hive_jar_version}, standalone-metastore/pom.xml

[sqoop]
build_tool = ant
COMMON_BUILD_OPTS = "${ANT_CMD} -Dmvn.version=2.1.3 -Dorc.version=${orc_jar_version} -Dhadoop.version=${hadoop_jar_version} -Dhbase.version=${hbase_jar_version} -Dkite-data.version=${kite_jar_version} -Dhcatalog.version=${hive_jar_version} -Dzookeeper.version=${zookeeper_jar_version} -Daccumulo.version=${accumulo_jar_version} -Dversion=${sqoop_jar_version} -Dhadoop.version.full=${hadoop_jar_version} -Dprev.git.hash=HEAD -Dtest.junit.output.format=xml -Dslf4j.version=1.6.1 -Dmvn.repo=${NEXUS_DEPLOY_REPO_ID} -Dmvn.repo.id=${NEXUS_DEPLOY_REPO_ID} -Dmvn.deploy.url=${NEXUS_REPO_URL} -Drepo.maven.org=${NEXUS_PROXY_URL} -Dsnapshot.apache.org=${NEXUS_PROXY_URL} -Dstaging.cloudera.com=${NEXUS_PROXY_URL} -Dreleases.cloudera.com=${NEXUS_PROXY_URL}"
deploy_cmd = ${COMMON_BUILD_OPTS} clean mvn-install mvn-deploy tar
package_count = 3
coverage_tool = cobertura

    [[artifacts]]
        artifact_1 = build/sqoop-${sqoop_jar_version}.bin__hadoop-${hadoop_jar_version}.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} clean mvn-install tar -Dmaven.javadoc.skip=true

    [[fortify_cmd]]
        cmd_1 = sourceanalyzer -b sqoop-${sqoop_jar_version} ${FORTIFY_SCAN_MEMORY} -verbose ${COMMON_BUILD_OPTS} clean mvn-install tar -Dmaven.javadoc.skip=true
        cmd_2 = sourceanalyzer -b sqoop-${sqoop_jar_version} ${FORTIFY_SCAN_MEMORY} -scan -f sqoop-${sqoop_jar_version}.fpr

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} clean test tar -Dmvn.version=2.1.3

    [[test_coverage_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} clean cobertura:cobertura tar -Dmvn.version=2.1.3

[shc]
build_tool = maven
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${shc_jar_version}

    [[artifacts]]
        artifact_1 = core/target/shc-core-${shc_jar_version}.jar

    [[install_cmd]]
        cmd_1 = ${MVN_CMD} clean install -Pscala-2.11 -DskipITs -DskipTests -Dmaven.javadoc.skip=true -Dreponame=${NEXUS_DEPLOY_REPO_ID} -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Drepourl=${NEXUS_PROXY_URL}

    [[xml-replace]]
        REPLACE_1 = 'hbase.version', ${hbase_jar_version}, pom.xml
        REPLACE_2 = 'spark.version', ${spark2_jar_version}, pom.xml
        REPLACE_3 = 'phoenix.version', ${phoenix_jar_version}, pom.xml

[hive_warehouse_connector]
build_tool = sbt

    [[artifacts]]
        artifact_1 = target/scala-2.11/hive-warehouse-connector-assembly-${hive_warehouse_connector_jar_version}.jar
        artifact_2 = target/pyspark_hwc-${hive_warehouse_connector_jar_version}.zip

    [[install_cmd]]
        cmd_1 = ./build/sbt compile -DskipTests -Dversion=${hive_warehouse_connector_jar_version} -Dspark.version=${spark2_jar_version} -Dhadoop.version=${hadoop_jar_version} -Dhive.version=${hive_jar_version} -Dtez.version=${tez_jar_version} -Drepourl=${NEXUS_PROXY_URL}
        cmd_2 = ./build/sbt  assembly -DskipTests -Dversion=${hive_warehouse_connector_jar_version} -Dspark.version=${spark2_jar_version} -Dhadoop.version=${hadoop_jar_version} -Dhive.version=${hive_jar_version} -Dtez.version=${tez_jar_version} -Drepourl=${NEXUS_PROXY_URL}
        cmd_3 = ./build/sbt  publishM2 -DskipTests -Dversion=${hive_warehouse_connector_jar_version} -Dspark.version=${spark2_jar_version} -Dhadoop.version=${hadoop_jar_version} -Dhive.version=${hive_jar_version} -Dtez.version=${tez_jar_version} -Drepourl=${NEXUS_PROXY_URL}

    [[text-replace]]
        REPLACE_1 = 'version :=.*', 'version := "${hive_warehouse_connector_jar_version}"', build.sbt, regex_replace
        REPLACE_2 = 'https://dl.bintray.com/typesafe/ivy-releases', 'http://172.22.94.86:8081/repository/sbt-ivy', build/sbt-launch-lib.bash, regex_replace

[storm]
build_tool = maven
storm_alternate_name = apache-storm
COMMON_BUILD_OPTS = "${MVN_CMD} -Dhive.version=${hive_jar_version} -Dzookeeper.version=${zookeeper_jar_version} -Dhadoop.version=${hadoop_jar_version} -Dhbase.version=${hbase_jar_version} -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Dreponame=${NEXUS_DEPLOY_REPO_ID} -Drepourl=${NEXUS_REPO_URL} -Drepo.maven.org=${NEXUS_PROXY_URL}"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${storm_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} clean package deploy -Pdist -Pgpg -Psign -DskipITs -DskipTests
BUILD_STORM_PACKAGING_OPTS =${COMMON_BUILD_OPTS} package -Pdist -Pgpg -DskipITs -DskipTests
package_count = 3

    [[artifacts]]
        artifact_1 = storm-dist/binary/target/${storm_alternate_name}-${storm_jar_version}.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} clean install -DskipITs -DskipTests -Pdist -Psign -Pgpg -Dmaven.javadoc.skip=true
        cmd_2 = ${COMMON_BUILD_OPTS} -DskipITs -DskipTests -Pnative -Dworker-launcher.conf.dir=/etc/storm/conf clean package
        cmd_3 = ${COMMON_BUILD_OPTS} package -Pdist -Pgpg -DskipITs -DskipTests , storm-dist/binary
        cmd_4 = ${COMMON_BUILD_OPTS} package -Pdist -Pgpg -DskipITs -DskipTests , storm-dist/source

    [[fortify_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} -DskipITs -DskipTests -Pdist -Psign -Pgpg -Dmaven.javadoc.skip=true clean install
        cmd_2 = ${COMMON_BUILD_OPTS} -DskipITs -DskipTests -Pdist -Psign -Pgpg -Dmaven.javadoc.skip=true ${FORTIFY_ARGS} -Dfortify.sca.buildId=storm-${storm_jar_version} ${FORTIFY_CLEAN_CMD}
        cmd_3 = ${COMMON_BUILD_OPTS} -DskipITs -DskipTests -Pdist -Psign -Pgpg -Dmaven.javadoc.skip=true ${FORTIFY_ARGS} -Dfortify.sca.buildId=storm-${storm_jar_version} ${FORTIFY_TRANSLATE_CMD}
        cmd_4 = sourceanalyzer -b storm-${storm_jar_version} ${FORTIFY_SCAN_MEMORY} -scan -f storm-${storm_jar_version}.fpr

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} ${MAVEN_TEST_OPTS} test

    [[text-replace]]
        REPLACE_1 = '2.4.0', ${hadoop_jar_version}, pom.xml , key_value

    [[xml-replace]]
        REPLACE_1 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'hbase.version', ${hbase_jar_version}, pom.xml
        REPLACE_3 = 'hive.version', ${hive_jar_version}, pom.xml
        REPLACE_4 = 'kafka.version', ${kafka_jar_version}, pom.xml
        REPLACE_5 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml
        REPLACE_6 = 'hdfs.version', ${hadoop_jar_version}, pom.xml
        REPLACE_7 = 'sigar.download.url', 'http://s3.amazonaws.com/dev.hortonworks.com/ARTIFACTS/hyperic-sigar-1.6.4.zip', external/storm-metrics/pom.xml
        REPLACE_8 = 'gcs.version' , ${gcs_jar_version} , pom.xml

[superset]
build_tool = npm
node_version = 5.11.1
N_PREFIX = ${HOME}/tools/n

    [[artifacts]]
        artifact_1 = superset-0.23.3-py34-none-linux_x86_64.wgn

    [[install_cmd]]
        cmd_1 = npm install n , superset/assets
        cmd_2 = bash -c "N_PREFIX=${N_PREFIX} node_modules/n/bin/n -q ${node_version}" , superset/assets
        cmd_3 = ${N_PREFIX}/n/versions/node/${node_version}/bin/npm install --loglevel=info , superset/assets
        cmd_4 = ${N_PREFIX}/n/versions/node/${node_version}/bin/node ${N_PREFIX}/n/versions/node/${node_version}/bin/npm run build --loglevel=info , superset/assets
        cmd_5 = ${BASE_DIR}/buildvenv/bin/wagon create . --format=tar.gz

    [[test_cmd]]
        cmd_1 = tox -e py34

[qe-examples]
build_tool = maven
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${qe-examples_jar_version}
deploy_cmd = ${MVN_CMD} package deploy -DskipTests -Dskip

    [[artifacts]]
        artifact_1 = spark2-examples-assembly/target/scala-2.11/jars/spark2-examples-assembly-${spark2_jar_version}.jar

    [[install_cmd]]
        cmd_1 = ${MVN_CMD} install -DskipITs -DskipTests -Dmaven.javadoc.skip=true -Dskip=true -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Dreponame=${NEXUS_DEPLOY_REPO_ID} -Drepourl=${NEXUS_REPO_URL}

    [[test_cmd]]
        cmd_1 = ${MVN_CMD} -fae test

    [[xml-replace]]
        #REPLACE_1 = 'flume.version', ${flume_jar_version}, pom.xml
        REPLACE_2 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_3 = 'hbase.version', ${hbase_jar_version}, pom.xml
        REPLACE_4 = 'protobuf.version', ${protobuf_version}, pom.xml
        REPLACE_5 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml
        REPLACE_6 = 'kafka.version', ${kafka_jar_version}, pom.xml
        REPLACE_7 = 'calcite.version', ${calcite_jar_version}, pom.xml
        REPLACE_8 = 'spark.version', ${spark2_jar_version}, pom.xml


# TODO (sriharsha) figure out spark version from pom.xml , BUG-58027 cached apache archive tar to s3.
# https://github.com/hortonworks/build-support/commit/6a258920f96f89aa7bec590734db69cf878c42a9
[zeppelin]
build_tool = maven
spark_pkg_version = 2.1.1
apache_spark_version = 2.2.0
COMMON_BUILD_OPTS = ${MVN_CMD} -Divy.home=${HOME}/.ivy2 -Dsbt.ivy.home=${HOME}/.ivy2 -Duser.home=${HOME} -Drepo.maven.org=${NEXUS_REPO_URL} -DaltDeploymentRepository=${NEXUS_DEPLOY_REPO_ID}::default::${NEXUS_REPO_URL} -Dreactor.repo='file://${HOME}/.m2/repository' -Pspark-2.2 -Pscala-2.11 -Dspark.version=${apache_spark_version} -Phadoop-2.7 -Dhadoop.version=${hadoop_jar_version} -Pyarn -Pbuild-distr -Psparkr -Drat.skip=True -Dspark.download.url=http://public-repo-1.hortonworks.com/ARTIFACTS/dist/spark/spark-${spark_pkg_version}/spark-${spark_pkg_version}.tgz -Dspark.bin.download.url=http://public-repo-1.hortonworks.com/ARTIFACTS/dist/spark/spark-${spark_pkg_version}/spark-${spark_pkg_version}-bin-without-hadoop.tgz -Pjdbc-hive -Pjdbc-phoenix -Pjdbc-hadoop3
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${zeppelin_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} deploy -DskipTests
coverage_tool = cobertura

    [[artifacts]]
      artifact_1 = zeppelin-distribution/target/zeppelin-${zeppelin_jar_version}.tar.gz

    [[install_cmd]]
      cmd_1 = ${COMMON_BUILD_OPTS} install -DskipTests

    [[fortify_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} install -DskipTests
        cmd_2 = ${COMMON_BUILD_OPTS} -DskipTests -DskipITs ${FORTIFY_ARGS} -Dfortify.sca.buildId=zeppelin-${zeppelin_jar_version} ${FORTIFY_CLEAN_CMD}
        cmd_3 = ${COMMON_BUILD_OPTS} -DskipTests -DskipITs ${FORTIFY_ARGS} -Dfortify.sca.buildId=zeppelin-${zeppelin_jar_version} ${FORTIFY_TRANSLATE_CMD}
        cmd_4 = sourceanalyzer -b zeppelin-${zeppelin_jar_version} ${FORTIFY_SCAN_MEMORY} -scan -f zeppelin-${zeppelin_jar_version}.fpr

    [[xml-replace]]
      REPLACE_1 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
      REPLACE_2 = 'hbase.hadoop.version', ${hadoop_jar_version}, pom.xml
      REPLACE_3 = 'hadoop-common.version', ${hadoop_jar_version}, pom.xml
      REPLACE_4 = 'hbase.version', ${hbase_jar_version}, pom.xml
      REPLACE_5 = 'hbase.hbase.version', ${hbase_jar_version}, pom.xml
      REPLACE_6 = 'spark.version', ${apache_spark_version}, pom.xml
      REPLACE_7 = 'protobuf.version', ${protobuf_version}, pom.xml
      REPLACE_8 = 'zookeeper.version' , ${zookeeper_jar_version} , pom.xml
      REPLACE_10 = 'hive.version', ${hive_jar_version}, jdbc/pom.xml
      REPLACE_11 = 'phoenix.version', ${phoenix_jar_version}, pom.xml
      REPLACE_12 = 'spark-hive.version', ${spark_hive2_jar_version}, jdbc/pom.xml
      REPLACE_13 = 'hive2.version', ${hive_jar_version}, jdbc/pom.xml
      REPLACE_14 = 'gcs.version' , ${gcs_jar_version} , zeppelin-zengine/pom.xml

    [[test_cmd]]
      cmd_1 = ${MVN_CMD} -Drat.skip=true -DfailIfNoTests=false -fae test

    [[test_coverage_cmd]]
      cmd_1 = ${MVN_CMD} -Drat.skip=true -DfailIfNoTests=false -fae cobertura:cobertura

[tez]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN_CMD} clean ${MAVEN_TEST_OPTS} -Dtar -Pgpg -Paws -Pazure -Pgcs -Phadoop28 -Psources -Dhadoop.version=${hadoop_jar_version} -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Dreponame=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.repository=${NEXUS_REPO_URL} -DdistMgmtStagingId=${NEXUS_DEPLOY_REPO_ID} -DdistMgmtStagingUrl=${NEXUS_REPO_URL}"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${tez_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} deploy
package_count = 2
coverage_tool = cobertura

    [[artifacts]]
        artifact_1 = tez-dist/target/tez-${tez_jar_version}-minimal.tar.gz
        artifact_2 = tez-dist/target/tez-${tez_jar_version}.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} install -DskipTests

    [[fortify_cmd]]
        cmd_1 = "${COMMON_BUILD_OPTS} -DskipITs -DskipTests install"
        cmd_2 = ${COMMON_BUILD_OPTS} -DskipTests -DskipITs -Dmaven.javadoc.skip=true ${FORTIFY_ARGS} -Dfortify.sca.buildId=tez-${tez_jar_version} ${FORTIFY_CLEAN_CMD}
        cmd_3 = ${COMMON_BUILD_OPTS} -DskipTests -DskipITs -Dmaven.javadoc.skip=true ${FORTIFY_ARGS} -Dfortify.sca.buildId=tez-${tez_jar_version} ${FORTIFY_TRANSLATE_CMD}
        cmd_4 = sourceanalyzer -b tez-${tez_jar_version} ${FORTIFY_SCAN_MEMORY} -scan -f tez-${tez_jar_version}.fpr

    [[test_cmd]]
        cmd_1 = npm set strict-ssl false ; ${MVN_CMD} test

    [[test_coverage_cmd]]
        cmd_1 = npm set strict-ssl false ; ${MVN_CMD} cobertura:cobertura

    [[xml-replace]]
        REPLACE_1 = 'hadoop.version', ${hadoop_jar_version}, pom.xml
        REPLACE_2 = 'zookeeper.version', ${zookeeper_jar_version}, pom.xml
        REPLACE_3 = 'gcs.version' , ${gcs_jar_version} , pom.xml


[zookeeper]
build_tool = ant
# TODO (Sriharsha) removed -Djavac.args=\'-Xlint -Xmaxwarns 1000\' due to quotes issue
COMMON_BUILD_OPTS ="${ANT_CMD}  -Dversion=${zookeeper_jar_version} -Dcppunit.m4=/usr/share/aclocal -Dtest.junit.output.format=xml  -DAM_PATH_CPPUNIT=/usr/lib64 -Drepo.maven.org=${NEXUS_PROXY_URL} -Drepo.jboss.org=${NEXUS_PROXY_URL} -Divy.url='http://central.maven.org/maven2/org/apache/ivy/ivy' -Dmvnrepo=${NEXUS_PROXY_URL}"
deploy_cmd = "${COMMON_BUILD_OPTS} -f nexus-build.xml -Dstaging_repo_id=${NEXUS_DEPLOY_REPO_ID} -Dstaging_repo_url=${NEXUS_REPO_URL} stage"
package_count = 3
coverage_tool = cobertura

    [[artifacts]]
        artifact_1 = build/zookeeper-${zookeeper_jar_version}.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} mvn-install
        cmd_2 = ${COMMON_BUILD_OPTS} -f build.xml tar

    [[fortify_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} mvn-install
        cmd_2 = ${COMMON_BUILD_OPTS} -f build.xml tar
    	cmd_3 = sourceanalyzer -b zookeeper-${zookeeper_jar_version} ${COMMON_BUILD_OPTS} clean mvn-install tar
        cmd_4 = sourceanalyzer -b zookeeper-${zookeeper_jar_version} ${FORTIFY_SCAN_MEMORY} -scan -f zookeeper-${zookeeper_jar_version}.fpr

    [[test_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} clean test -Djunit.default.timeout=5000

    [[test_coverage_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} clean cobertura-test -Djunit.default.timeout=5000


[knox]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN_CMD}  -Ppackage,release,analyze -DskipCheck=true -Dcheckstyle.skip=true -Drepo.id=${NEXUS_DEPLOY_REPO_ID} -Dinternal.maven.repo=${NEXUS_REPO_URL}"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${knox_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS}  deploy -DskipITs -DskipTests
package = 2
coverage_tool = cobertura

    [[artifacts]]
        artifact_1 = target/${knox_jar_version}/knox-${knox_jar_version}.tar.gz

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} install -DskipITs -DskipTests -Dmaven.javadoc.skip=true -Dmaven.test.skip=true

    [[fortify_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} install -DskipITs -DskipTests -Dmaven.javadoc.skip=true -Dmaven.test.skip=true
        cmd_2 = ${COMMON_BUILD_OPTS} -DskipITs -DskipTests -Dmaven.javadoc.skip=true -Dmaven.test.skip=true ${FORTIFY_ARGS} -Dfortify.sca.buildId=knox-${knox_jar_version} ${FORTIFY_CLEAN_CMD}
        cmd_3 = ${COMMON_BUILD_OPTS} -DskipITs -DskipTests -Dmaven.javadoc.skip=true -Dmaven.test.skip=true ${FORTIFY_ARGS} -Dfortify.sca.buildId=knox-${knox_jar_version} ${FORTIFY_TRANSLATE_CMD}
    	cmd_4 = sourceanalyzer -b knox-${knox_jar_version} ${FORTIFY_SCAN_MEMORY} -scan -f knox-${knox_jar_version}.fpr

    [[test_cmd]]
        cmd_1 = "${MVN_CMD} -DskipTests=false -Panalyze,package,release install"

    [[test_coverage_cmd]]
        cmd_1 = "${MVN_CMD} -DskipTests=false -Panalyze,package,release cobertura:cobertura"

    [[xml-replace]]
    REPLACE_1 = 'gateway-version', ${knox_jar_version}, pom.xml
    REPLACE_2 = 'hadoop-version', ${hadoop_jar_version}, pom.xml
    REPLACE_3 = 'zookeeper-version', ${zookeeper_jar_version}, pom.xml

[kite]
build_tool = maven
COMMON_BUILD_OPTS = "${MVN_CMD} -Drepoid=${NEXUS_DEPLOY_REPO_ID} -Drepourl=${NEXUS_REPO_URL} clean"
setversion_cmd = ${MVN_CMD} ${MVN_SET_VERSION_CMD} -DnewVersion=${kite_jar_version}
deploy_cmd = ${COMMON_BUILD_OPTS} deploy -DskipTests=true -Dmaven.javadoc.skip=true

    [[install_cmd]]
        cmd_1 = ${COMMON_BUILD_OPTS} install -DskipTests=true

    [[xml-replace]]
    REPLACE_1 = 'vers.hive', ${hive_jar_version}, pom.xml
